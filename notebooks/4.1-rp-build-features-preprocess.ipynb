{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.definitions import ROOT_DIR, LITHOLOGY_ORDINAL_MAP\n",
    "from src.features.build_features import replace_nan_inf, shift_concat, gradient, shift_concat_gradient\n",
    "from src.features.build_features import build_encoding_map, label_encode_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olawale preprocess\n",
    "\n",
    "The competition winner employs the following steps to preprocess the data:\n",
    "\n",
    "\n",
    "1. Grab target and map it to scoring matrix index (lithology_ordinal).\n",
    "\n",
    "2. Drop columns with uncommon logs.\n",
    "\n",
    "3. Encode Group, Formation, and Well names. In my opinion, we should drop the well names before training.\n",
    "\n",
    "4. Fill mising values with -999. I think XGBoost can handle missing values. Alternatively, we could use a fancier imputation method.\n",
    "\n",
    "5. Drop target column.\n",
    "\n",
    "6. Augment features usign Bestagini's functions.\n",
    "\n",
    "7. Return augmented features and lithology ordinal\n",
    "\n",
    "In this notebook I explore each step, before wrinting the resulting strategy as a `preprocess` method in the `Model` class. Also, Olawale preprocessed the train and test data in the same method. I'd like to create the preprocess method for the train set, and then apply it to both train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = ROOT_DIR / 'data/external' / 'CSV_train.csv'\n",
    "\n",
    "assert train_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WELL</th>\n",
       "      <th>DEPTH_MD</th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>Z_LOC</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>FORMATION</th>\n",
       "      <th>CALI</th>\n",
       "      <th>RSHA</th>\n",
       "      <th>RMED</th>\n",
       "      <th>...</th>\n",
       "      <th>ROP</th>\n",
       "      <th>DTS</th>\n",
       "      <th>DCAL</th>\n",
       "      <th>DRHO</th>\n",
       "      <th>MUDWEIGHT</th>\n",
       "      <th>RMIC</th>\n",
       "      <th>ROPA</th>\n",
       "      <th>RXO</th>\n",
       "      <th>FORCE_2020_LITHOFACIES_LITHOLOGY</th>\n",
       "      <th>FORCE_2020_LITHOFACIES_CONFIDENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>617715</th>\n",
       "      <td>31/3-2</td>\n",
       "      <td>1137.000901</td>\n",
       "      <td>536841.25000</td>\n",
       "      <td>6748638.0</td>\n",
       "      <td>-1111.950317</td>\n",
       "      <td>ROGALAND GP.</td>\n",
       "      <td>Balder Fm.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.967944</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807371</th>\n",
       "      <td>34/10-35</td>\n",
       "      <td>3682.135000</td>\n",
       "      <td>463451.81250</td>\n",
       "      <td>6771074.5</td>\n",
       "      <td>-3654.509766</td>\n",
       "      <td>CROMER KNOLL GP.</td>\n",
       "      <td>Vaale Fm.</td>\n",
       "      <td>14.945340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.598644</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.282708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65030</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104401</th>\n",
       "      <td>16/11-1 ST3</td>\n",
       "      <td>1727.761201</td>\n",
       "      <td>474592.40625</td>\n",
       "      <td>6436512.0</td>\n",
       "      <td>-1697.702271</td>\n",
       "      <td>SHETLAND GP.</td>\n",
       "      <td>Hod Fm.</td>\n",
       "      <td>12.466503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.693021</td>\n",
       "      <td>...</td>\n",
       "      <td>38.602707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.162316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70032</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026725</th>\n",
       "      <td>35/11-6</td>\n",
       "      <td>1220.519600</td>\n",
       "      <td>525013.25000</td>\n",
       "      <td>6784873.0</td>\n",
       "      <td>-1193.318115</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>Utsira Fm.</td>\n",
       "      <td>18.749014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.258404</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050818</th>\n",
       "      <td>35/11-7</td>\n",
       "      <td>1805.278000</td>\n",
       "      <td>531919.56250</td>\n",
       "      <td>6766801.0</td>\n",
       "      <td>-1776.225342</td>\n",
       "      <td>VIKING GP.</td>\n",
       "      <td>Sognefjord Fm.</td>\n",
       "      <td>8.565600</td>\n",
       "      <td>5.227934</td>\n",
       "      <td>7.559114</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110001</th>\n",
       "      <td>35/8-6 S</td>\n",
       "      <td>3408.158800</td>\n",
       "      <td>518338.03125</td>\n",
       "      <td>6798681.0</td>\n",
       "      <td>-3066.321777</td>\n",
       "      <td>SHETLAND GP.</td>\n",
       "      <td>Tryggvason Fm.</td>\n",
       "      <td>12.422927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.325142</td>\n",
       "      <td>...</td>\n",
       "      <td>33.061623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.475971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094896</th>\n",
       "      <td>35/4-1</td>\n",
       "      <td>4635.284000</td>\n",
       "      <td>516178.75000</td>\n",
       "      <td>6822415.5</td>\n",
       "      <td>-4603.724609</td>\n",
       "      <td>DUNLIN GP.</td>\n",
       "      <td>Amundsen Fm.</td>\n",
       "      <td>8.752624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.547599</td>\n",
       "      <td>...</td>\n",
       "      <td>8.416300</td>\n",
       "      <td>124.002060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65030</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773100</th>\n",
       "      <td>34/10-21</td>\n",
       "      <td>2232.762403</td>\n",
       "      <td>454140.53125</td>\n",
       "      <td>6777267.5</td>\n",
       "      <td>-2203.421143</td>\n",
       "      <td>SHETLAND GP.</td>\n",
       "      <td>Jorsalfare Fm.</td>\n",
       "      <td>14.530687</td>\n",
       "      <td>0.881725</td>\n",
       "      <td>1.178219</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.883196</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168866</th>\n",
       "      <td>7/1-2 S</td>\n",
       "      <td>2920.032400</td>\n",
       "      <td>444920.34375</td>\n",
       "      <td>6421580.5</td>\n",
       "      <td>-2859.183594</td>\n",
       "      <td>TYNE GP.</td>\n",
       "      <td>Farsund Fm.</td>\n",
       "      <td>8.739972</td>\n",
       "      <td>3.646720</td>\n",
       "      <td>3.433068</td>\n",
       "      <td>...</td>\n",
       "      <td>24.850914</td>\n",
       "      <td>140.566620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.188253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089935</th>\n",
       "      <td>35/4-1</td>\n",
       "      <td>3880.908000</td>\n",
       "      <td>516101.59375</td>\n",
       "      <td>6822434.5</td>\n",
       "      <td>-3854.122803</td>\n",
       "      <td>VIKING GP.</td>\n",
       "      <td>Heather Fm.</td>\n",
       "      <td>9.294566</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.090889</td>\n",
       "      <td>...</td>\n",
       "      <td>4.998700</td>\n",
       "      <td>212.982147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                WELL     DEPTH_MD         X_LOC      Y_LOC        Z_LOC  \\\n",
       "617715        31/3-2  1137.000901  536841.25000  6748638.0 -1111.950317   \n",
       "807371      34/10-35  3682.135000  463451.81250  6771074.5 -3654.509766   \n",
       "104401   16/11-1 ST3  1727.761201  474592.40625  6436512.0 -1697.702271   \n",
       "1026725      35/11-6  1220.519600  525013.25000  6784873.0 -1193.318115   \n",
       "1050818      35/11-7  1805.278000  531919.56250  6766801.0 -1776.225342   \n",
       "1110001     35/8-6 S  3408.158800  518338.03125  6798681.0 -3066.321777   \n",
       "1094896       35/4-1  4635.284000  516178.75000  6822415.5 -4603.724609   \n",
       "773100      34/10-21  2232.762403  454140.53125  6777267.5 -2203.421143   \n",
       "1168866      7/1-2 S  2920.032400  444920.34375  6421580.5 -2859.183594   \n",
       "1089935       35/4-1  3880.908000  516101.59375  6822434.5 -3854.122803   \n",
       "\n",
       "                    GROUP       FORMATION       CALI      RSHA      RMED  ...  \\\n",
       "617715       ROGALAND GP.      Balder Fm.        NaN       NaN  0.967944  ...   \n",
       "807371   CROMER KNOLL GP.       Vaale Fm.  14.945340       NaN  1.598644  ...   \n",
       "104401       SHETLAND GP.         Hod Fm.  12.466503       NaN  1.693021  ...   \n",
       "1026725     HORDALAND GP.      Utsira Fm.  18.749014       NaN  1.258404  ...   \n",
       "1050818        VIKING GP.  Sognefjord Fm.   8.565600  5.227934  7.559114  ...   \n",
       "1110001      SHETLAND GP.  Tryggvason Fm.  12.422927       NaN  2.325142  ...   \n",
       "1094896        DUNLIN GP.    Amundsen Fm.   8.752624       NaN  6.547599  ...   \n",
       "773100       SHETLAND GP.  Jorsalfare Fm.  14.530687  0.881725  1.178219  ...   \n",
       "1168866          TYNE GP.     Farsund Fm.   8.739972  3.646720  3.433068  ...   \n",
       "1089935        VIKING GP.     Heather Fm.   9.294566       NaN  2.090889  ...   \n",
       "\n",
       "               ROP         DTS  DCAL      DRHO  MUDWEIGHT  RMIC       ROPA  \\\n",
       "617715         NaN         NaN   NaN -0.004689        NaN   NaN        NaN   \n",
       "807371         NaN         NaN   NaN -0.282708        NaN   NaN        NaN   \n",
       "104401   38.602707         NaN   NaN       NaN   1.162316   NaN        NaN   \n",
       "1026725        NaN         NaN   NaN -0.002806        NaN   NaN        NaN   \n",
       "1050818        NaN         NaN   NaN  0.013399        NaN   NaN        NaN   \n",
       "1110001  33.061623         NaN   NaN  0.031794        NaN   NaN  26.475971   \n",
       "1094896   8.416300  124.002060   NaN -0.006907        NaN   NaN        NaN   \n",
       "773100         NaN         NaN   NaN -0.005447        NaN   NaN        NaN   \n",
       "1168866  24.850914  140.566620   NaN       NaN        NaN   NaN  30.188253   \n",
       "1089935   4.998700  212.982147   NaN -0.003790        NaN   NaN        NaN   \n",
       "\n",
       "              RXO  FORCE_2020_LITHOFACIES_LITHOLOGY  \\\n",
       "617715        NaN                             65000   \n",
       "807371        NaN                             65030   \n",
       "104401        NaN                             70032   \n",
       "1026725       NaN                             65000   \n",
       "1050818       NaN                             30000   \n",
       "1110001       NaN                             65000   \n",
       "1094896       NaN                             65030   \n",
       "773100   0.883196                             65000   \n",
       "1168866       NaN                             30000   \n",
       "1089935       NaN                             65000   \n",
       "\n",
       "         FORCE_2020_LITHOFACIES_CONFIDENCE  \n",
       "617715                                 2.0  \n",
       "807371                                 1.0  \n",
       "104401                                 2.0  \n",
       "1026725                                1.0  \n",
       "1050818                                1.0  \n",
       "1110001                                1.0  \n",
       "1094896                                1.0  \n",
       "773100                                 1.0  \n",
       "1168866                                2.0  \n",
       "1089935                                1.0  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1170511, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WELL', 'DEPTH_MD', 'X_LOC', 'Y_LOC', 'Z_LOC', 'GROUP', 'FORMATION',\n",
       "       'CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'SGR', 'NPHI', 'PEF',\n",
       "       'DTC', 'SP', 'BS', 'ROP', 'DTS', 'DCAL', 'DRHO', 'MUDWEIGHT', 'RMIC',\n",
       "       'ROPA', 'RXO', 'FORCE_2020_LITHOFACIES_LITHOLOGY',\n",
       "       'FORCE_2020_LITHOFACIES_CONFIDENCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab target and map it to scoring matrix index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lith_codes = df['FORCE_2020_LITHOFACIES_LITHOLOGY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lith_ordinal = lith_codes.map(LITHOLOGY_ORDINAL_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop target column\n",
    "This should be done outside the preprocess method. This way, we can preprocess both train and test set with the same method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('FORCE_2020_LITHOFACIES_LITHOLOGY', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop columns with uncommon logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of missing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGR                                  0.940750\n",
       "DTS                                  0.850823\n",
       "RMIC                                 0.849502\n",
       "ROPA                                 0.835691\n",
       "DCAL                                 0.744699\n",
       "MUDWEIGHT                            0.729903\n",
       "RXO                                  0.720270\n",
       "ROP                                  0.542874\n",
       "RSHA                                 0.461218\n",
       "PEF                                  0.426155\n",
       "BS                                   0.416787\n",
       "NPHI                                 0.346090\n",
       "SP                                   0.261650\n",
       "DRHO                                 0.156046\n",
       "RHOB                                 0.137777\n",
       "FORMATION                            0.117038\n",
       "CALI                                 0.075076\n",
       "DTC                                  0.069084\n",
       "RMED                                 0.033313\n",
       "RDEP                                 0.009410\n",
       "Z_LOC                                0.009205\n",
       "Y_LOC                                0.009205\n",
       "X_LOC                                0.009205\n",
       "GROUP                                0.001092\n",
       "FORCE_2020_LITHOFACIES_CONFIDENCE    0.000153\n",
       "DEPTH_MD                             0.000000\n",
       "GR                                   0.000000\n",
       "WELL                                 0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = (df.isna().sum() / df.shape[0]).sort_values(ascending=False)\n",
    "\n",
    "print('Percent of missing values')\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list we can see that there are a few logs with high rate of missing values. Let's drop those with more than 50% missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SGR', 'DTS', 'RMIC', 'ROPA', 'DCAL', 'MUDWEIGHT', 'RXO', 'ROP']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_cutoff = 0.5\n",
    "cols = missing_values[missing_values > missing_value_cutoff].index.to_list()\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drop columns in the competition winner code are:\n",
    "\n",
    "| Drop column |\n",
    "| ----------- |\n",
    "|FORCE_2020_LITHOFACIES_CONFIDENCE|\n",
    "|SGR|\n",
    "|DTS|\n",
    "|RXO|\n",
    "|ROPA|\n",
    "\n",
    "There is some overlap with the columns found using the 50% cutoff on the missing values. The main discrepancy is the column `FORCE_2020_LITHOFACIES_CONFIDENCE`. This column is meant to assing a certainty value (ordinal) to the lithology interpretation. However, it will not be present in the prediction data (test) and thus it can't be used directly in the training. I'll drop it here, but it will be interesting to explore how to use it during training in future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.append('FORCE_2020_LITHOFACIES_CONFIDENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1170511, 19)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WELL          object\n",
       "DEPTH_MD     float64\n",
       "X_LOC        float64\n",
       "Y_LOC        float64\n",
       "Z_LOC        float64\n",
       "GROUP         object\n",
       "FORMATION     object\n",
       "CALI         float64\n",
       "RSHA         float64\n",
       "RMED         float64\n",
       "RDEP         float64\n",
       "RHOB         float64\n",
       "GR           float64\n",
       "NPHI         float64\n",
       "PEF          float64\n",
       "DTC          float64\n",
       "SP           float64\n",
       "BS           float64\n",
       "DRHO         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WELL', 'GROUP', 'FORMATION'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cat_columns = df.select_dtypes(include='object').columns\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The well name column `WELL` is important for referencing the sample but should not carry information about the lithologies it contains. Let's not encode it.\n",
    "\n",
    "Also, the `GROUP` and `FORMATION` columns could carry a lot of information about the target lithology, however, including these in the model could make it less robust for application in areas where these formations and groups don't exists (e.g. a different basin) or are named differently. In this case, I will encode them trying to stay close to Olawale's work, but in the future I'd like to test the effect of droppoing these columns in the model's score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['GROUP', 'FORMATION'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cat_columns = cat_columns.drop('WELL')\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GROUP</th>\n",
       "      <th>FORMATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GROUP FORMATION\n",
       "0  NORDLAND GP.       NaN\n",
       "1  NORDLAND GP.       NaN\n",
       "2  NORDLAND GP.       NaN\n",
       "3  NORDLAND GP.       NaN\n",
       "4  NORDLAND GP.       NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = df.loc[:, cat_columns]\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cat['GROUP'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HORDALAND GP.       0.250450\n",
       "SHETLAND GP.        0.199937\n",
       "VIKING GP.          0.112770\n",
       "ROGALAND GP.        0.112723\n",
       "DUNLIN GP.          0.101738\n",
       "NORDLAND GP.        0.095249\n",
       "CROMER KNOLL GP.    0.044698\n",
       "BAAT GP.            0.030605\n",
       "VESTLAND GP.        0.022312\n",
       "HEGRE GP.           0.011886\n",
       "ZECHSTEIN GP.       0.010455\n",
       "BOKNFJORD GP.       0.002670\n",
       "ROTLIEGENDES GP.    0.002385\n",
       "NaN                 0.001092\n",
       "TYNE GP.            0.001029\n",
       "Name: GROUP, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['GROUP'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent of missing values in GROUP is: 0.1092%\n"
     ]
    }
   ],
   "source": [
    "group_missing_perc = df_cat['GROUP'].isna().sum() / len(df_cat['GROUP'])\n",
    "\n",
    "print(f'The percent of missing values in GROUP is: {group_missing_perc*100:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formation missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cat['FORMATION'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Utsira Fm.               0.147488\n",
       "NaN                      0.117038\n",
       "Kyrre Fm.                0.080587\n",
       "Lista Fm.                0.060726\n",
       "Heather Fm.              0.055566\n",
       "                           ...   \n",
       "Broom Fm.                0.000201\n",
       "Intra Balder Fm. Sst.    0.000151\n",
       "Farsund Fm.              0.000146\n",
       "Flekkefjord Fm.          0.000101\n",
       "Egersund Fm.             0.000090\n",
       "Name: FORMATION, Length: 70, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['FORMATION'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent of missing values in GROUP is: 11.7038%\n"
     ]
    }
   ],
   "source": [
    "formation_missing_perc = df_cat['FORMATION'].isna().sum() / len(df_cat['FORMATION'])\n",
    "print(f'The percent of missing values in GROUP is: {formation_missing_perc*100:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encode\n",
    "The competition winner uses a label encoder in pandas. Since the model is tree-based and there is high cardinality in the formation column (70 unique categories), this is a reasonable compromise. Later, we could try to use one hot encoding to test the effect in the model score.\n",
    "\n",
    "Also, Olawale approach used -1 to mark missing values. In this case, I'll use numpy.nan instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NORDLAND GP.': 0,\n",
       " 'HORDALAND GP.': 1,\n",
       " 'ROGALAND GP.': 2,\n",
       " 'SHETLAND GP.': 3,\n",
       " 'CROMER KNOLL GP.': 4,\n",
       " 'VIKING GP.': 5,\n",
       " 'VESTLAND GP.': 6,\n",
       " 'ZECHSTEIN GP.': 7,\n",
       " 'HEGRE GP.': 8,\n",
       " 'ROTLIEGENDES GP.': 9,\n",
       " 'TYNE GP.': 10,\n",
       " 'BOKNFJORD GP.': 11,\n",
       " 'DUNLIN GP.': 12,\n",
       " 'BAAT GP.': 13}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_mapping = build_encoding_map(df_cat['GROUP'])\n",
    "group_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Utsira Fm.': 1,\n",
       " 'Balder Fm.': 2,\n",
       " 'Sele Fm.': 3,\n",
       " 'Lista Fm.': 4,\n",
       " 'Heimdal Fm.': 5,\n",
       " 'Tor Fm.': 6,\n",
       " 'Hod Fm.': 7,\n",
       " 'Blodoeks Fm.': 8,\n",
       " 'Svarte Fm.': 9,\n",
       " 'Roedby Fm.': 10,\n",
       " 'Sola Fm.': 11,\n",
       " 'Aasgard Fm.': 12,\n",
       " 'Draupne Fm.': 13,\n",
       " 'Heather Fm.': 14,\n",
       " 'Hugin Fm.': 15,\n",
       " 'Smith Bank Fm.': 16,\n",
       " 'Frigg Fm.': 17,\n",
       " 'Skagerrak Fm.': 18,\n",
       " 'Ekofisk Fm.': 19,\n",
       " 'Kupferschiefer Fm.': 20,\n",
       " 'Skade Fm.': 21,\n",
       " 'Grid Fm.': 22,\n",
       " 'Vaale Fm.': 23,\n",
       " 'Sleipner Fm.': 24,\n",
       " 'Hidra Fm.': 25,\n",
       " 'Tuxen Fm.': 26,\n",
       " 'Mandal Fm.': 27,\n",
       " 'Ula Fm.': 28,\n",
       " 'Bryne Fm.': 29,\n",
       " 'Tau Fm.': 30,\n",
       " 'Sandnes Fm.': 31,\n",
       " 'Intra Draupne Fm. Sst.': 32,\n",
       " 'Statfjord Fm.': 33,\n",
       " 'Skade Mb.': 34,\n",
       " 'BASEMENT': 35,\n",
       " 'Ran Sst Mb.': 36,\n",
       " 'Flekkefjord Fm.': 37,\n",
       " 'Sauda Fm.': 38,\n",
       " 'Egersund Fm.': 39,\n",
       " 'Intra Balder Fm. Sst.': 40,\n",
       " 'Hermod Mb.': 41,\n",
       " 'Ty Fm.': 42,\n",
       " 'Hardraade Fm.': 43,\n",
       " 'Kyrre Fm.': 44,\n",
       " 'Tryggvason Fm.': 45,\n",
       " 'Drake Fm.': 46,\n",
       " 'Cook Fm.': 47,\n",
       " 'Amundsen Fm.': 48,\n",
       " 'Grid Mb.': 49,\n",
       " 'Ty Mb.': 50,\n",
       " 'Jorsalfare Fm.': 51,\n",
       " 'Burton Fm.': 52,\n",
       " 'Mime Fm.': 53,\n",
       " 'Intra Heather Fm. Sst.': 54,\n",
       " 'Tarbert Fm.': 55,\n",
       " 'Ness Fm.': 56,\n",
       " 'Etive Fm.': 57,\n",
       " 'Rannoch Fm.': 58,\n",
       " 'Broom Fm.': 59,\n",
       " 'Lunde Fm.': 60,\n",
       " 'Oseberg Fm.': 61,\n",
       " 'Sognefjord Fm.': 62,\n",
       " 'Fensfjord Fm.': 63,\n",
       " 'Krossfjord Fm.': 64,\n",
       " 'Johansen Fm.': 65,\n",
       " 'Eiriksson Mb.': 66,\n",
       " 'Raude Mb.': 67,\n",
       " 'Agat Fm.': 68,\n",
       " 'Farsund Fm.': 69}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formation_mapping = build_encoding_map(df_cat['FORMATION'])\n",
    "formation_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {col: build_encoding_map(df_cat[col]) for col in df_cat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = label_encode_columns(df, cat_columns, mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WELL</th>\n",
       "      <th>DEPTH_MD</th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>Z_LOC</th>\n",
       "      <th>CALI</th>\n",
       "      <th>RSHA</th>\n",
       "      <th>RMED</th>\n",
       "      <th>RDEP</th>\n",
       "      <th>RHOB</th>\n",
       "      <th>GR</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>PEF</th>\n",
       "      <th>DTC</th>\n",
       "      <th>SP</th>\n",
       "      <th>BS</th>\n",
       "      <th>DRHO</th>\n",
       "      <th>GROUP_encoded</th>\n",
       "      <th>FORMATION_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.528</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.501831</td>\n",
       "      <td>19.480835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.611410</td>\n",
       "      <td>1.798681</td>\n",
       "      <td>1.884186</td>\n",
       "      <td>80.200851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.915468</td>\n",
       "      <td>161.131180</td>\n",
       "      <td>24.612379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.574928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.680</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.653809</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.618070</td>\n",
       "      <td>1.795641</td>\n",
       "      <td>1.889794</td>\n",
       "      <td>79.262886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.383013</td>\n",
       "      <td>160.603470</td>\n",
       "      <td>23.895531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.570188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.832</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.805786</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.626459</td>\n",
       "      <td>1.800733</td>\n",
       "      <td>1.896523</td>\n",
       "      <td>74.821999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.591518</td>\n",
       "      <td>160.173615</td>\n",
       "      <td>23.916357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.574245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.984</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.957794</td>\n",
       "      <td>19.459282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.621594</td>\n",
       "      <td>1.801517</td>\n",
       "      <td>1.891913</td>\n",
       "      <td>72.878922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.191910</td>\n",
       "      <td>160.149429</td>\n",
       "      <td>23.793688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.586315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>495.136</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-470.109772</td>\n",
       "      <td>19.453100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.602679</td>\n",
       "      <td>1.795299</td>\n",
       "      <td>1.880034</td>\n",
       "      <td>71.729141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.495632</td>\n",
       "      <td>160.128342</td>\n",
       "      <td>24.104078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.597914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WELL  DEPTH_MD         X_LOC      Y_LOC       Z_LOC       CALI  RSHA  \\\n",
       "0  15/9-13   494.528  437641.96875  6470972.5 -469.501831  19.480835   NaN   \n",
       "1  15/9-13   494.680  437641.96875  6470972.5 -469.653809  19.468800   NaN   \n",
       "2  15/9-13   494.832  437641.96875  6470972.5 -469.805786  19.468800   NaN   \n",
       "3  15/9-13   494.984  437641.96875  6470972.5 -469.957794  19.459282   NaN   \n",
       "4  15/9-13   495.136  437641.96875  6470972.5 -470.109772  19.453100   NaN   \n",
       "\n",
       "       RMED      RDEP      RHOB         GR  NPHI        PEF         DTC  \\\n",
       "0  1.611410  1.798681  1.884186  80.200851   NaN  20.915468  161.131180   \n",
       "1  1.618070  1.795641  1.889794  79.262886   NaN  19.383013  160.603470   \n",
       "2  1.626459  1.800733  1.896523  74.821999   NaN  22.591518  160.173615   \n",
       "3  1.621594  1.801517  1.891913  72.878922   NaN  32.191910  160.149429   \n",
       "4  1.602679  1.795299  1.880034  71.729141   NaN  38.495632  160.128342   \n",
       "\n",
       "          SP  BS      DRHO  GROUP_encoded  FORMATION_encoded  \n",
       "0  24.612379 NaN -0.574928            0.0                NaN  \n",
       "1  23.895531 NaN -0.570188            0.0                NaN  \n",
       "2  23.916357 NaN -0.574245            0.0                NaN  \n",
       "3  23.793688 NaN -0.586315            0.0                NaN  \n",
       "4  24.104078 NaN -0.597914            0.0                NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute missing values\n",
    "In the winning code, the missing values are filled with three different values:\n",
    "\n",
    "1. -999: For missing values in the raw logs.\n",
    "2. 0: This is used in Bestagini's feature augmentation to fill missing values created by these functions.\n",
    "3. -1: This is use in the encoding of the categorical columns.\n",
    "\n",
    "In my case, I'll use numpy.nan for these three cases. Since XGboost can handle missing data, I think it is an acceptable first pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment features usign Bestagini's functions.\n",
    "In notebook 4.0, I explore Bestagini's functions originally written using numpy, and compare them to my pandas version. Here, I incorporate my pandas version of these functions to the preprocess method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocesed = shift_concat_gradient(df_encoded, 'DEPTH_MD', 'WELL', periods=1, fill_value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_LOC_shifted_1</th>\n",
       "      <th>Y_LOC_shifted_1</th>\n",
       "      <th>Z_LOC_shifted_1</th>\n",
       "      <th>CALI_shifted_1</th>\n",
       "      <th>RSHA_shifted_1</th>\n",
       "      <th>RMED_shifted_1</th>\n",
       "      <th>RDEP_shifted_1</th>\n",
       "      <th>RHOB_shifted_1</th>\n",
       "      <th>GR_shifted_1</th>\n",
       "      <th>NPHI_shifted_1</th>\n",
       "      <th>...</th>\n",
       "      <th>RHOB_gradient</th>\n",
       "      <th>GR_gradient</th>\n",
       "      <th>NPHI_gradient</th>\n",
       "      <th>PEF_gradient</th>\n",
       "      <th>DTC_gradient</th>\n",
       "      <th>SP_gradient</th>\n",
       "      <th>BS_gradient</th>\n",
       "      <th>DRHO_gradient</th>\n",
       "      <th>GROUP_encoded_gradient</th>\n",
       "      <th>FORMATION_encoded_gradient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.501831</td>\n",
       "      <td>19.480835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.611410</td>\n",
       "      <td>1.798681</td>\n",
       "      <td>1.884186</td>\n",
       "      <td>80.200851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036893</td>\n",
       "      <td>-6.170825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.081944</td>\n",
       "      <td>-3.471776</td>\n",
       "      <td>-4.716108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.653809</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.618070</td>\n",
       "      <td>1.795641</td>\n",
       "      <td>1.889794</td>\n",
       "      <td>79.262886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044271</td>\n",
       "      <td>-29.216365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.108590</td>\n",
       "      <td>-2.827996</td>\n",
       "      <td>0.137015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.026689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.805786</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.626459</td>\n",
       "      <td>1.800733</td>\n",
       "      <td>1.896523</td>\n",
       "      <td>74.821999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030329</td>\n",
       "      <td>-12.783402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.160470</td>\n",
       "      <td>-0.159113</td>\n",
       "      <td>-0.807034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.079409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.957794</td>\n",
       "      <td>19.459282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.621594</td>\n",
       "      <td>1.801517</td>\n",
       "      <td>1.891913</td>\n",
       "      <td>72.878922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078150</td>\n",
       "      <td>-7.564344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.471858</td>\n",
       "      <td>-0.138735</td>\n",
       "      <td>2.042043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.076305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_LOC_shifted_1  Y_LOC_shifted_1  Z_LOC_shifted_1  CALI_shifted_1  \\\n",
       "0              NaN              NaN              NaN             NaN   \n",
       "1     437641.96875        6470972.5      -469.501831       19.480835   \n",
       "2     437641.96875        6470972.5      -469.653809       19.468800   \n",
       "3     437641.96875        6470972.5      -469.805786       19.468800   \n",
       "4     437641.96875        6470972.5      -469.957794       19.459282   \n",
       "\n",
       "   RSHA_shifted_1  RMED_shifted_1  RDEP_shifted_1  RHOB_shifted_1  \\\n",
       "0             NaN             NaN             NaN             NaN   \n",
       "1             NaN        1.611410        1.798681        1.884186   \n",
       "2             NaN        1.618070        1.795641        1.889794   \n",
       "3             NaN        1.626459        1.800733        1.896523   \n",
       "4             NaN        1.621594        1.801517        1.891913   \n",
       "\n",
       "   GR_shifted_1  NPHI_shifted_1  ...  RHOB_gradient  GR_gradient  \\\n",
       "0           NaN             NaN  ...            NaN          NaN   \n",
       "1     80.200851             NaN  ...       0.036893    -6.170825   \n",
       "2     79.262886             NaN  ...       0.044271   -29.216365   \n",
       "3     74.821999             NaN  ...      -0.030329   -12.783402   \n",
       "4     72.878922             NaN  ...      -0.078150    -7.564344   \n",
       "\n",
       "   NPHI_gradient  PEF_gradient  DTC_gradient  SP_gradient  BS_gradient  \\\n",
       "0            NaN           NaN           NaN          NaN          NaN   \n",
       "1            NaN    -10.081944     -3.471776    -4.716108          NaN   \n",
       "2            NaN     21.108590     -2.827996     0.137015          NaN   \n",
       "3            NaN     63.160470     -0.159113    -0.807034          NaN   \n",
       "4            NaN     41.471858     -0.138735     2.042043          NaN   \n",
       "\n",
       "   DRHO_gradient  GROUP_encoded_gradient  FORMATION_encoded_gradient  \n",
       "0            NaN                     NaN                         NaN  \n",
       "1       0.031179                     0.0                         NaN  \n",
       "2      -0.026689                     0.0                         NaN  \n",
       "3      -0.079409                     0.0                         NaN  \n",
       "4      -0.076305                     0.0                         NaN  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocesed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1170511, 70)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocesed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X_LOC_shifted_1               float64\n",
       "Y_LOC_shifted_1               float64\n",
       "Z_LOC_shifted_1               float64\n",
       "CALI_shifted_1                float64\n",
       "RSHA_shifted_1                float64\n",
       "                               ...   \n",
       "SP_gradient                   float64\n",
       "BS_gradient                   float64\n",
       "DRHO_gradient                 float64\n",
       "GROUP_encoded_gradient        float64\n",
       "FORMATION_encoded_gradient    float64\n",
       "Length: 70, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocesed.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lith_pred",
   "language": "python",
   "name": "lith_pred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
