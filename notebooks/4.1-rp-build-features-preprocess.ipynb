{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.definitions import ROOT_DIR, LITHOLOGY_ORDINAL_MAP\n",
    "from src.features.build_features import replace_nan_inf, shift_concat, gradient, shift_concat_gradient\n",
    "from src.features.build_features import build_encoding_map, label_encode_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olawale preprocess\n",
    "\n",
    "The competition winner employs the following steps to preprocess the data:\n",
    "\n",
    "\n",
    "1. Grab target and map it to scoring matrix index (lithology_ordinal).\n",
    "\n",
    "2. Drop columns with uncommon logs.\n",
    "\n",
    "3. Encode Group, Formation, and Well names. In my opinion, we should drop the well names before training.\n",
    "\n",
    "4. Fill mising values with -999. I think XGBoost can handle missing values. Alternatively, we could use a fancier imputation method.\n",
    "\n",
    "5. Drop target column.\n",
    "\n",
    "6. Augment features usign Bestagini's functions.\n",
    "\n",
    "7. Return augmented features and lithology ordinal\n",
    "\n",
    "In this notebook I explore each step, before wrinting the resulting strategy as a `preprocess` method in the `Model` class. Also, Olawale preprocessed the train and test data in the same method. I'd like to create the preprocess method for the train set, and then apply it to both train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = ROOT_DIR / 'data/external' / 'CSV_train.csv'\n",
    "\n",
    "assert train_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WELL</th>\n",
       "      <th>DEPTH_MD</th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>Z_LOC</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>FORMATION</th>\n",
       "      <th>CALI</th>\n",
       "      <th>RSHA</th>\n",
       "      <th>RMED</th>\n",
       "      <th>...</th>\n",
       "      <th>ROP</th>\n",
       "      <th>DTS</th>\n",
       "      <th>DCAL</th>\n",
       "      <th>DRHO</th>\n",
       "      <th>MUDWEIGHT</th>\n",
       "      <th>RMIC</th>\n",
       "      <th>ROPA</th>\n",
       "      <th>RXO</th>\n",
       "      <th>FORCE_2020_LITHOFACIES_LITHOLOGY</th>\n",
       "      <th>FORCE_2020_LITHOFACIES_CONFIDENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67454</th>\n",
       "      <td>16/10-1</td>\n",
       "      <td>1770.935790</td>\n",
       "      <td>444152.25000</td>\n",
       "      <td>6435554.0</td>\n",
       "      <td>-1745.860840</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>Utsira Fm.</td>\n",
       "      <td>12.344602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701079</td>\n",
       "      <td>...</td>\n",
       "      <td>11.337502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.155399</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.158171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490150</th>\n",
       "      <td>29/6-1</td>\n",
       "      <td>4504.537001</td>\n",
       "      <td>444357.90625</td>\n",
       "      <td>6711915.0</td>\n",
       "      <td>-4452.953613</td>\n",
       "      <td>DUNLIN GP.</td>\n",
       "      <td>Drake Fm.</td>\n",
       "      <td>10.473240</td>\n",
       "      <td>0.242730</td>\n",
       "      <td>3.016226</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.245306</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670031</th>\n",
       "      <td>31/5-4 S</td>\n",
       "      <td>1253.566000</td>\n",
       "      <td>530689.43750</td>\n",
       "      <td>6732035.5</td>\n",
       "      <td>-1226.862671</td>\n",
       "      <td>ROGALAND GP.</td>\n",
       "      <td>Balder Fm.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753193</th>\n",
       "      <td>34/10-19</td>\n",
       "      <td>832.832000</td>\n",
       "      <td>460122.90625</td>\n",
       "      <td>6783932.5</td>\n",
       "      <td>-810.797119</td>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.807139</td>\n",
       "      <td>0.889961</td>\n",
       "      <td>1.482796</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.199382</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030346</th>\n",
       "      <td>35/11-6</td>\n",
       "      <td>1770.911600</td>\n",
       "      <td>524993.75000</td>\n",
       "      <td>6784874.5</td>\n",
       "      <td>-1743.360596</td>\n",
       "      <td>ROGALAND GP.</td>\n",
       "      <td>Lista Fm.</td>\n",
       "      <td>18.125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.956199</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>341.762329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.015203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529913</th>\n",
       "      <td>30/6-5</td>\n",
       "      <td>2104.482400</td>\n",
       "      <td>497432.90625</td>\n",
       "      <td>6728312.5</td>\n",
       "      <td>-2079.449219</td>\n",
       "      <td>ROGALAND GP.</td>\n",
       "      <td>Sele Fm.</td>\n",
       "      <td>12.890290</td>\n",
       "      <td>0.602892</td>\n",
       "      <td>0.833076</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.646123</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62948</th>\n",
       "      <td>16/10-1</td>\n",
       "      <td>1086.023790</td>\n",
       "      <td>444151.25000</td>\n",
       "      <td>6435550.0</td>\n",
       "      <td>-1060.974731</td>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>Utsira Fm.</td>\n",
       "      <td>18.180176</td>\n",
       "      <td>0.688474</td>\n",
       "      <td>1.088438</td>\n",
       "      <td>...</td>\n",
       "      <td>15.644161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.144990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.690368</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071598</th>\n",
       "      <td>35/3-7 S</td>\n",
       "      <td>3345.195851</td>\n",
       "      <td>543908.68750</td>\n",
       "      <td>6856661.0</td>\n",
       "      <td>-3241.015869</td>\n",
       "      <td>CROMER KNOLL GP.</td>\n",
       "      <td>Roedby Fm.</td>\n",
       "      <td>8.502975</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.863734</td>\n",
       "      <td>...</td>\n",
       "      <td>21.474884</td>\n",
       "      <td>155.889160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.024436</td>\n",
       "      <td>16.938353</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879837</th>\n",
       "      <td>34/5-1 A</td>\n",
       "      <td>2430.849992</td>\n",
       "      <td>478823.46875</td>\n",
       "      <td>6845744.5</td>\n",
       "      <td>-2397.033203</td>\n",
       "      <td>SHETLAND GP.</td>\n",
       "      <td>Kyrre Fm.</td>\n",
       "      <td>12.341754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.308896</td>\n",
       "      <td>...</td>\n",
       "      <td>50.191223</td>\n",
       "      <td>283.067108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.151161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041568</th>\n",
       "      <td>35/11-6</td>\n",
       "      <td>3476.655600</td>\n",
       "      <td>524983.06250</td>\n",
       "      <td>6784908.5</td>\n",
       "      <td>-3448.385986</td>\n",
       "      <td>VIKING GP.</td>\n",
       "      <td>Heather Fm.</td>\n",
       "      <td>9.210300</td>\n",
       "      <td>7.513116</td>\n",
       "      <td>6.097899</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             WELL     DEPTH_MD         X_LOC      Y_LOC        Z_LOC  \\\n",
       "67454     16/10-1  1770.935790  444152.25000  6435554.0 -1745.860840   \n",
       "490150     29/6-1  4504.537001  444357.90625  6711915.0 -4452.953613   \n",
       "670031   31/5-4 S  1253.566000  530689.43750  6732035.5 -1226.862671   \n",
       "753193   34/10-19   832.832000  460122.90625  6783932.5  -810.797119   \n",
       "1030346   35/11-6  1770.911600  524993.75000  6784874.5 -1743.360596   \n",
       "529913     30/6-5  2104.482400  497432.90625  6728312.5 -2079.449219   \n",
       "62948     16/10-1  1086.023790  444151.25000  6435550.0 -1060.974731   \n",
       "1071598  35/3-7 S  3345.195851  543908.68750  6856661.0 -3241.015869   \n",
       "879837   34/5-1 A  2430.849992  478823.46875  6845744.5 -2397.033203   \n",
       "1041568   35/11-6  3476.655600  524983.06250  6784908.5 -3448.385986   \n",
       "\n",
       "                    GROUP    FORMATION       CALI      RSHA      RMED  ...  \\\n",
       "67454       HORDALAND GP.   Utsira Fm.  12.344602       NaN  0.701079  ...   \n",
       "490150         DUNLIN GP.    Drake Fm.  10.473240  0.242730  3.016226  ...   \n",
       "670031       ROGALAND GP.   Balder Fm.        NaN       NaN       NaN  ...   \n",
       "753193       NORDLAND GP.          NaN  14.807139  0.889961  1.482796  ...   \n",
       "1030346      ROGALAND GP.    Lista Fm.  18.125000       NaN  0.956199  ...   \n",
       "529913       ROGALAND GP.     Sele Fm.  12.890290  0.602892  0.833076  ...   \n",
       "62948        NORDLAND GP.   Utsira Fm.  18.180176  0.688474  1.088438  ...   \n",
       "1071598  CROMER KNOLL GP.   Roedby Fm.   8.502975       NaN  4.863734  ...   \n",
       "879837       SHETLAND GP.    Kyrre Fm.  12.341754       NaN  1.308896  ...   \n",
       "1041568        VIKING GP.  Heather Fm.   9.210300  7.513116  6.097899  ...   \n",
       "\n",
       "               ROP         DTS      DCAL      DRHO  MUDWEIGHT      RMIC  \\\n",
       "67454    11.337502         NaN -0.155399  0.009076   0.158171       NaN   \n",
       "490150         NaN         NaN       NaN  0.049607        NaN       NaN   \n",
       "670031         NaN         NaN       NaN       NaN        NaN       NaN   \n",
       "753193         NaN         NaN       NaN  0.103021        NaN       NaN   \n",
       "1030346        NaN  341.762329       NaN -0.015203        NaN       NaN   \n",
       "529913         NaN         NaN       NaN -0.002395        NaN       NaN   \n",
       "62948    15.644161         NaN  0.710029       NaN   0.144990       NaN   \n",
       "1071598  21.474884  155.889160       NaN -0.008651        NaN  5.024436   \n",
       "879837   50.191223  283.067108       NaN  0.026764        NaN       NaN   \n",
       "1041568        NaN         NaN       NaN  0.000022        NaN       NaN   \n",
       "\n",
       "              ROPA       RXO  FORCE_2020_LITHOFACIES_LITHOLOGY  \\\n",
       "67454          NaN       NaN                             65000   \n",
       "490150         NaN  0.245306                             65000   \n",
       "670031         NaN       NaN                             99000   \n",
       "753193         NaN  1.199382                             65000   \n",
       "1030346        NaN       NaN                             65000   \n",
       "529913         NaN  0.646123                             65000   \n",
       "62948          NaN  0.690368                             65000   \n",
       "1071598  16.938353       NaN                             30000   \n",
       "879837   41.151161       NaN                             65000   \n",
       "1041568        NaN       NaN                             65000   \n",
       "\n",
       "         FORCE_2020_LITHOFACIES_CONFIDENCE  \n",
       "67454                                  1.0  \n",
       "490150                                 1.0  \n",
       "670031                                 3.0  \n",
       "753193                                 1.0  \n",
       "1030346                                1.0  \n",
       "529913                                 1.0  \n",
       "62948                                  1.0  \n",
       "1071598                                1.0  \n",
       "879837                                 1.0  \n",
       "1041568                                1.0  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1170511, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WELL', 'DEPTH_MD', 'X_LOC', 'Y_LOC', 'Z_LOC', 'GROUP', 'FORMATION',\n",
       "       'CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'SGR', 'NPHI', 'PEF',\n",
       "       'DTC', 'SP', 'BS', 'ROP', 'DTS', 'DCAL', 'DRHO', 'MUDWEIGHT', 'RMIC',\n",
       "       'ROPA', 'RXO', 'FORCE_2020_LITHOFACIES_LITHOLOGY',\n",
       "       'FORCE_2020_LITHOFACIES_CONFIDENCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab target and map it to scoring matrix index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lith_codes = df['FORCE_2020_LITHOFACIES_LITHOLOGY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lith_ordinal = lith_codes.map(LITHOLOGY_ORDINAL_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop target column\n",
    "This should be done outside the preprocess method. This way, we can preprocess both train and test set with the same method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('FORCE_2020_LITHOFACIES_LITHOLOGY', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop columns with uncommon logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of missing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGR                                  0.940750\n",
       "DTS                                  0.850823\n",
       "RMIC                                 0.849502\n",
       "ROPA                                 0.835691\n",
       "DCAL                                 0.744699\n",
       "MUDWEIGHT                            0.729903\n",
       "RXO                                  0.720270\n",
       "ROP                                  0.542874\n",
       "RSHA                                 0.461218\n",
       "PEF                                  0.426155\n",
       "BS                                   0.416787\n",
       "NPHI                                 0.346090\n",
       "SP                                   0.261650\n",
       "DRHO                                 0.156046\n",
       "RHOB                                 0.137777\n",
       "FORMATION                            0.117038\n",
       "CALI                                 0.075076\n",
       "DTC                                  0.069084\n",
       "RMED                                 0.033313\n",
       "RDEP                                 0.009410\n",
       "Z_LOC                                0.009205\n",
       "Y_LOC                                0.009205\n",
       "X_LOC                                0.009205\n",
       "GROUP                                0.001092\n",
       "FORCE_2020_LITHOFACIES_CONFIDENCE    0.000153\n",
       "DEPTH_MD                             0.000000\n",
       "GR                                   0.000000\n",
       "WELL                                 0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = (df.isna().sum() / df.shape[0]).sort_values(ascending=False)\n",
    "\n",
    "print('Percent of missing values')\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list we can see that there are a few logs with high rate of missing values. Let's drop those with more than 50% missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SGR', 'DTS', 'RMIC', 'ROPA', 'DCAL', 'MUDWEIGHT', 'RXO', 'ROP']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_cutoff = 0.5\n",
    "cols = missing_values[missing_values > missing_value_cutoff].index.to_list()\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drop columns in the competition winner code are:\n",
    "\n",
    "| Drop column |\n",
    "| ----------- |\n",
    "|FORCE_2020_LITHOFACIES_CONFIDENCE|\n",
    "|SGR|\n",
    "|DTS|\n",
    "|RXO|\n",
    "|ROPA|\n",
    "\n",
    "There is some overlap with the columns found using the 50% cutoff on the missing values. The main discrepancy is the column `FORCE_2020_LITHOFACIES_CONFIDENCE`. This column is meant to assing a certainty value (ordinal) to the lithology interpretation. However, it will not be present in the prediction data (test) and thus it can't be used directly in the training. I'll drop it here, but it will be interesting to explore how to use it during training in future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.append('FORCE_2020_LITHOFACIES_CONFIDENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1170511, 19)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WELL          object\n",
       "DEPTH_MD     float64\n",
       "X_LOC        float64\n",
       "Y_LOC        float64\n",
       "Z_LOC        float64\n",
       "GROUP         object\n",
       "FORMATION     object\n",
       "CALI         float64\n",
       "RSHA         float64\n",
       "RMED         float64\n",
       "RDEP         float64\n",
       "RHOB         float64\n",
       "GR           float64\n",
       "NPHI         float64\n",
       "PEF          float64\n",
       "DTC          float64\n",
       "SP           float64\n",
       "BS           float64\n",
       "DRHO         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WELL', 'GROUP', 'FORMATION'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cat_columns = df.select_dtypes(include='object').columns\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The well name column `WELL` is important for referencing the sample but should not carry information about the lithologies it contains. Let's not encode it.\n",
    "\n",
    "Also, the `GROUP` and `FORMATION` columns could carry a lot of information about the target lithology, however, including these in the model could make it less robust for application in areas where these formations and groups don't exists (e.g. a different basin) or are named differently. In this case, I will encode them trying to stay close to Olawale's work, but in the future I'd like to test the effect of droppoing these columns in the model's score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['GROUP', 'FORMATION'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cat_columns= cat_columns.drop('WELL')\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GROUP</th>\n",
       "      <th>FORMATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GROUP FORMATION\n",
       "0  NORDLAND GP.       NaN\n",
       "1  NORDLAND GP.       NaN\n",
       "2  NORDLAND GP.       NaN\n",
       "3  NORDLAND GP.       NaN\n",
       "4  NORDLAND GP.       NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = df.loc[:, cat_columns]\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cat['GROUP'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HORDALAND GP.       0.250450\n",
       "SHETLAND GP.        0.199937\n",
       "VIKING GP.          0.112770\n",
       "ROGALAND GP.        0.112723\n",
       "DUNLIN GP.          0.101738\n",
       "NORDLAND GP.        0.095249\n",
       "CROMER KNOLL GP.    0.044698\n",
       "BAAT GP.            0.030605\n",
       "VESTLAND GP.        0.022312\n",
       "HEGRE GP.           0.011886\n",
       "ZECHSTEIN GP.       0.010455\n",
       "BOKNFJORD GP.       0.002670\n",
       "ROTLIEGENDES GP.    0.002385\n",
       "NaN                 0.001092\n",
       "TYNE GP.            0.001029\n",
       "Name: GROUP, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['GROUP'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent of missing values in GROUP is: 0.1092%\n"
     ]
    }
   ],
   "source": [
    "group_missing_perc = df_cat['GROUP'].isna().sum() / len(df_cat['GROUP'])\n",
    "\n",
    "print(f'The percent of missing values in GROUP is: {group_missing_perc*100:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formation missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cat['FORMATION'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Utsira Fm.               0.147488\n",
       "NaN                      0.117038\n",
       "Kyrre Fm.                0.080587\n",
       "Lista Fm.                0.060726\n",
       "Heather Fm.              0.055566\n",
       "                           ...   \n",
       "Broom Fm.                0.000201\n",
       "Intra Balder Fm. Sst.    0.000151\n",
       "Farsund Fm.              0.000146\n",
       "Flekkefjord Fm.          0.000101\n",
       "Egersund Fm.             0.000090\n",
       "Name: FORMATION, Length: 70, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['FORMATION'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent of missing values in GROUP is: 11.7038%\n"
     ]
    }
   ],
   "source": [
    "formation_missing_perc = df_cat['FORMATION'].isna().sum() / len(df_cat['FORMATION'])\n",
    "print(f'The percent of missing values in GROUP is: {formation_missing_perc*100:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encode\n",
    "The competition winner uses a label encoder in pandas. Since the model is tree-based and there is high cardinality in the formation column (70 unique categories), this is a reasonable compromise. Later, we could try to use one hot encoding to test the effect in the model score.\n",
    "\n",
    "Also, Olawale approach used -1 to mark missing values. In this case, I'll use numpy.nan instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NORDLAND GP.': 0,\n",
       " 'HORDALAND GP.': 1,\n",
       " 'ROGALAND GP.': 2,\n",
       " 'SHETLAND GP.': 3,\n",
       " 'CROMER KNOLL GP.': 4,\n",
       " 'VIKING GP.': 5,\n",
       " 'VESTLAND GP.': 6,\n",
       " 'ZECHSTEIN GP.': 7,\n",
       " 'HEGRE GP.': 8,\n",
       " 'ROTLIEGENDES GP.': 9,\n",
       " 'TYNE GP.': 10,\n",
       " 'BOKNFJORD GP.': 11,\n",
       " 'DUNLIN GP.': 12,\n",
       " 'BAAT GP.': 13}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_mapping = build_encoding_map(df_cat['GROUP'])\n",
    "group_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Utsira Fm.': 1,\n",
       " 'Balder Fm.': 2,\n",
       " 'Sele Fm.': 3,\n",
       " 'Lista Fm.': 4,\n",
       " 'Heimdal Fm.': 5,\n",
       " 'Tor Fm.': 6,\n",
       " 'Hod Fm.': 7,\n",
       " 'Blodoeks Fm.': 8,\n",
       " 'Svarte Fm.': 9,\n",
       " 'Roedby Fm.': 10,\n",
       " 'Sola Fm.': 11,\n",
       " 'Aasgard Fm.': 12,\n",
       " 'Draupne Fm.': 13,\n",
       " 'Heather Fm.': 14,\n",
       " 'Hugin Fm.': 15,\n",
       " 'Smith Bank Fm.': 16,\n",
       " 'Frigg Fm.': 17,\n",
       " 'Skagerrak Fm.': 18,\n",
       " 'Ekofisk Fm.': 19,\n",
       " 'Kupferschiefer Fm.': 20,\n",
       " 'Skade Fm.': 21,\n",
       " 'Grid Fm.': 22,\n",
       " 'Vaale Fm.': 23,\n",
       " 'Sleipner Fm.': 24,\n",
       " 'Hidra Fm.': 25,\n",
       " 'Tuxen Fm.': 26,\n",
       " 'Mandal Fm.': 27,\n",
       " 'Ula Fm.': 28,\n",
       " 'Bryne Fm.': 29,\n",
       " 'Tau Fm.': 30,\n",
       " 'Sandnes Fm.': 31,\n",
       " 'Intra Draupne Fm. Sst.': 32,\n",
       " 'Statfjord Fm.': 33,\n",
       " 'Skade Mb.': 34,\n",
       " 'BASEMENT': 35,\n",
       " 'Ran Sst Mb.': 36,\n",
       " 'Flekkefjord Fm.': 37,\n",
       " 'Sauda Fm.': 38,\n",
       " 'Egersund Fm.': 39,\n",
       " 'Intra Balder Fm. Sst.': 40,\n",
       " 'Hermod Mb.': 41,\n",
       " 'Ty Fm.': 42,\n",
       " 'Hardraade Fm.': 43,\n",
       " 'Kyrre Fm.': 44,\n",
       " 'Tryggvason Fm.': 45,\n",
       " 'Drake Fm.': 46,\n",
       " 'Cook Fm.': 47,\n",
       " 'Amundsen Fm.': 48,\n",
       " 'Grid Mb.': 49,\n",
       " 'Ty Mb.': 50,\n",
       " 'Jorsalfare Fm.': 51,\n",
       " 'Burton Fm.': 52,\n",
       " 'Mime Fm.': 53,\n",
       " 'Intra Heather Fm. Sst.': 54,\n",
       " 'Tarbert Fm.': 55,\n",
       " 'Ness Fm.': 56,\n",
       " 'Etive Fm.': 57,\n",
       " 'Rannoch Fm.': 58,\n",
       " 'Broom Fm.': 59,\n",
       " 'Lunde Fm.': 60,\n",
       " 'Oseberg Fm.': 61,\n",
       " 'Sognefjord Fm.': 62,\n",
       " 'Fensfjord Fm.': 63,\n",
       " 'Krossfjord Fm.': 64,\n",
       " 'Johansen Fm.': 65,\n",
       " 'Eiriksson Mb.': 66,\n",
       " 'Raude Mb.': 67,\n",
       " 'Agat Fm.': 68,\n",
       " 'Farsund Fm.': 69}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formation_mapping = build_encoding_map(df_cat['FORMATION'])\n",
    "formation_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {col: build_encoding_map(df_cat[col]) for col in df_cat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = label_encode_columns(df, cat_columns, mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WELL</th>\n",
       "      <th>DEPTH_MD</th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>Z_LOC</th>\n",
       "      <th>CALI</th>\n",
       "      <th>RSHA</th>\n",
       "      <th>RMED</th>\n",
       "      <th>RDEP</th>\n",
       "      <th>RHOB</th>\n",
       "      <th>GR</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>PEF</th>\n",
       "      <th>DTC</th>\n",
       "      <th>SP</th>\n",
       "      <th>BS</th>\n",
       "      <th>DRHO</th>\n",
       "      <th>GROUP_encoded</th>\n",
       "      <th>FORMATION_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.528</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.501831</td>\n",
       "      <td>19.480835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.611410</td>\n",
       "      <td>1.798681</td>\n",
       "      <td>1.884186</td>\n",
       "      <td>80.200851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.915468</td>\n",
       "      <td>161.131180</td>\n",
       "      <td>24.612379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.574928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.680</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.653809</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.618070</td>\n",
       "      <td>1.795641</td>\n",
       "      <td>1.889794</td>\n",
       "      <td>79.262886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.383013</td>\n",
       "      <td>160.603470</td>\n",
       "      <td>23.895531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.570188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.832</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.805786</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.626459</td>\n",
       "      <td>1.800733</td>\n",
       "      <td>1.896523</td>\n",
       "      <td>74.821999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.591518</td>\n",
       "      <td>160.173615</td>\n",
       "      <td>23.916357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.574245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.984</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.957794</td>\n",
       "      <td>19.459282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.621594</td>\n",
       "      <td>1.801517</td>\n",
       "      <td>1.891913</td>\n",
       "      <td>72.878922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.191910</td>\n",
       "      <td>160.149429</td>\n",
       "      <td>23.793688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.586315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>495.136</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-470.109772</td>\n",
       "      <td>19.453100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.602679</td>\n",
       "      <td>1.795299</td>\n",
       "      <td>1.880034</td>\n",
       "      <td>71.729141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.495632</td>\n",
       "      <td>160.128342</td>\n",
       "      <td>24.104078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.597914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WELL  DEPTH_MD         X_LOC      Y_LOC       Z_LOC       CALI  RSHA  \\\n",
       "0  15/9-13   494.528  437641.96875  6470972.5 -469.501831  19.480835   NaN   \n",
       "1  15/9-13   494.680  437641.96875  6470972.5 -469.653809  19.468800   NaN   \n",
       "2  15/9-13   494.832  437641.96875  6470972.5 -469.805786  19.468800   NaN   \n",
       "3  15/9-13   494.984  437641.96875  6470972.5 -469.957794  19.459282   NaN   \n",
       "4  15/9-13   495.136  437641.96875  6470972.5 -470.109772  19.453100   NaN   \n",
       "\n",
       "       RMED      RDEP      RHOB         GR  NPHI        PEF         DTC  \\\n",
       "0  1.611410  1.798681  1.884186  80.200851   NaN  20.915468  161.131180   \n",
       "1  1.618070  1.795641  1.889794  79.262886   NaN  19.383013  160.603470   \n",
       "2  1.626459  1.800733  1.896523  74.821999   NaN  22.591518  160.173615   \n",
       "3  1.621594  1.801517  1.891913  72.878922   NaN  32.191910  160.149429   \n",
       "4  1.602679  1.795299  1.880034  71.729141   NaN  38.495632  160.128342   \n",
       "\n",
       "          SP  BS      DRHO GROUP_encoded FORMATION_encoded  \n",
       "0  24.612379 NaN -0.574928           0.0               NaN  \n",
       "1  23.895531 NaN -0.570188           0.0               NaN  \n",
       "2  23.916357 NaN -0.574245           0.0               NaN  \n",
       "3  23.793688 NaN -0.586315           0.0               NaN  \n",
       "4  24.104078 NaN -0.597914           0.0               NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute missing values\n",
    "In the winning code, the missing values are filled with three different values:\n",
    "\n",
    "1. -999: For missing values in the raw logs.\n",
    "2. 0: This is used in Bestagini's feature augmentation to fill missing values created by these functions.\n",
    "3. -1: This is use in the encoding of the categorical columns.\n",
    "\n",
    "In my case, I'll use numpy.nan for these three cases. Since XGboost can handle missing data, I think it is an acceptable first pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment features usign Bestagini's functions.\n",
    "In notebook 4.0, I explore Bestagini's functions originally written using numpy, and compare them to my pandas version. Here, I incorporate my pandas version of these functions to the preprocess method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocesed = shift_concat_gradient(df_encoded, 'DEPTH_MD', 'WELL', periods=1, fill_value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_LOC_shifted_1</th>\n",
       "      <th>Y_LOC_shifted_1</th>\n",
       "      <th>Z_LOC_shifted_1</th>\n",
       "      <th>CALI_shifted_1</th>\n",
       "      <th>RSHA_shifted_1</th>\n",
       "      <th>RMED_shifted_1</th>\n",
       "      <th>RDEP_shifted_1</th>\n",
       "      <th>RHOB_shifted_1</th>\n",
       "      <th>GR_shifted_1</th>\n",
       "      <th>NPHI_shifted_1</th>\n",
       "      <th>...</th>\n",
       "      <th>RMED_gradient</th>\n",
       "      <th>RDEP_gradient</th>\n",
       "      <th>RHOB_gradient</th>\n",
       "      <th>GR_gradient</th>\n",
       "      <th>NPHI_gradient</th>\n",
       "      <th>PEF_gradient</th>\n",
       "      <th>DTC_gradient</th>\n",
       "      <th>SP_gradient</th>\n",
       "      <th>BS_gradient</th>\n",
       "      <th>DRHO_gradient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.501831</td>\n",
       "      <td>19.480835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.611410</td>\n",
       "      <td>1.798681</td>\n",
       "      <td>1.884186</td>\n",
       "      <td>80.200851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043819</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>0.036893</td>\n",
       "      <td>-6.170825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.081944</td>\n",
       "      <td>-3.471776</td>\n",
       "      <td>-4.716108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.653809</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.618070</td>\n",
       "      <td>1.795641</td>\n",
       "      <td>1.889794</td>\n",
       "      <td>79.262886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055186</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.044271</td>\n",
       "      <td>-29.216365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.108590</td>\n",
       "      <td>-2.827996</td>\n",
       "      <td>0.137015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.026689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.805786</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.626459</td>\n",
       "      <td>1.800733</td>\n",
       "      <td>1.896523</td>\n",
       "      <td>74.821999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032003</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>-0.030329</td>\n",
       "      <td>-12.783402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.160470</td>\n",
       "      <td>-0.159113</td>\n",
       "      <td>-0.807034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.079409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.957794</td>\n",
       "      <td>19.459282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.621594</td>\n",
       "      <td>1.801517</td>\n",
       "      <td>1.891913</td>\n",
       "      <td>72.878922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124441</td>\n",
       "      <td>-0.040905</td>\n",
       "      <td>-0.078150</td>\n",
       "      <td>-7.564344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.471858</td>\n",
       "      <td>-0.138735</td>\n",
       "      <td>2.042043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.076305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_LOC_shifted_1  Y_LOC_shifted_1  Z_LOC_shifted_1  CALI_shifted_1  \\\n",
       "0              NaN              NaN              NaN             NaN   \n",
       "1     437641.96875        6470972.5      -469.501831       19.480835   \n",
       "2     437641.96875        6470972.5      -469.653809       19.468800   \n",
       "3     437641.96875        6470972.5      -469.805786       19.468800   \n",
       "4     437641.96875        6470972.5      -469.957794       19.459282   \n",
       "\n",
       "   RSHA_shifted_1  RMED_shifted_1  RDEP_shifted_1  RHOB_shifted_1  \\\n",
       "0             NaN             NaN             NaN             NaN   \n",
       "1             NaN        1.611410        1.798681        1.884186   \n",
       "2             NaN        1.618070        1.795641        1.889794   \n",
       "3             NaN        1.626459        1.800733        1.896523   \n",
       "4             NaN        1.621594        1.801517        1.891913   \n",
       "\n",
       "   GR_shifted_1  NPHI_shifted_1  ...  RMED_gradient  RDEP_gradient  \\\n",
       "0           NaN             NaN  ...            NaN            NaN   \n",
       "1     80.200851             NaN  ...       0.043819      -0.020000   \n",
       "2     79.262886             NaN  ...       0.055186       0.033500   \n",
       "3     74.821999             NaN  ...      -0.032003       0.005153   \n",
       "4     72.878922             NaN  ...      -0.124441      -0.040905   \n",
       "\n",
       "   RHOB_gradient  GR_gradient  NPHI_gradient PEF_gradient DTC_gradient  \\\n",
       "0            NaN          NaN            NaN          NaN          NaN   \n",
       "1       0.036893    -6.170825            NaN   -10.081944    -3.471776   \n",
       "2       0.044271   -29.216365            NaN    21.108590    -2.827996   \n",
       "3      -0.030329   -12.783402            NaN    63.160470    -0.159113   \n",
       "4      -0.078150    -7.564344            NaN    41.471858    -0.138735   \n",
       "\n",
       "   SP_gradient  BS_gradient  DRHO_gradient  \n",
       "0          NaN          NaN            NaN  \n",
       "1    -4.716108          NaN       0.031179  \n",
       "2     0.137015          NaN      -0.026689  \n",
       "3    -0.807034          NaN      -0.079409  \n",
       "4     2.042043          NaN      -0.076305  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocesed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1170511, 68)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocesed.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lith_pred",
   "language": "python",
   "name": "lith_pred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
