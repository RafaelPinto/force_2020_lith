{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.definitions import ROOT_DIR, LITHOLOGY_ORDINAL_MAP\n",
    "from src.features.build_features import replace_nan_inf, shift_concat, gradient, shift_concat_gradient\n",
    "from src.features.build_features import build_encoding_map, label_encode_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olawale preprocess\n",
    "\n",
    "The competition winner employs the following steps to preprocess the data:\n",
    "\n",
    "\n",
    "1. Grab target and map it to scoring matrix index (lithology_ordinal).\n",
    "\n",
    "2. Drop columns with uncommon logs.\n",
    "\n",
    "3. Encode Group, Formation, and Well names. In my opinion, we should drop the well names before training.\n",
    "\n",
    "4. Fill mising values with -999. I think XGBoost can handle missing values. Alternatively, we could use a fancier imputation method.\n",
    "\n",
    "5. Drop target column.\n",
    "\n",
    "6. Augment features usign Bestagini's functions.\n",
    "\n",
    "7. Return augmented features and lithology ordinal\n",
    "\n",
    "In this notebook I explore each step, before wrinting the resulting strategy as a `preprocess` method in the `Model` class. Also, Olawale preprocessed the train and test data in the same method. I'd like to create the preprocess method for the train set, and then apply it to both train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = ROOT_DIR / 'data/external' / 'CSV_train.csv'\n",
    "\n",
    "assert train_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WELL</th>\n",
       "      <th>DEPTH_MD</th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>Z_LOC</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>FORMATION</th>\n",
       "      <th>CALI</th>\n",
       "      <th>RSHA</th>\n",
       "      <th>RMED</th>\n",
       "      <th>...</th>\n",
       "      <th>ROP</th>\n",
       "      <th>DTS</th>\n",
       "      <th>DCAL</th>\n",
       "      <th>DRHO</th>\n",
       "      <th>MUDWEIGHT</th>\n",
       "      <th>RMIC</th>\n",
       "      <th>ROPA</th>\n",
       "      <th>RXO</th>\n",
       "      <th>FORCE_2020_LITHOFACIES_LITHOLOGY</th>\n",
       "      <th>FORCE_2020_LITHOFACIES_CONFIDENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1050250</th>\n",
       "      <td>35/11-7</td>\n",
       "      <td>1717.270000</td>\n",
       "      <td>531919.12500</td>\n",
       "      <td>6766800.0</td>\n",
       "      <td>-1688.224243</td>\n",
       "      <td>ROGALAND GP.</td>\n",
       "      <td>Vaale Fm.</td>\n",
       "      <td>13.276628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.865714</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011558</th>\n",
       "      <td>35/11-12</td>\n",
       "      <td>2604.402000</td>\n",
       "      <td>520565.84375</td>\n",
       "      <td>6777349.0</td>\n",
       "      <td>-2580.281006</td>\n",
       "      <td>SHETLAND GP.</td>\n",
       "      <td>Kyrre Fm.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.120980</td>\n",
       "      <td>...</td>\n",
       "      <td>32.112389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578123</th>\n",
       "      <td>31/2-8</td>\n",
       "      <td>1391.996979</td>\n",
       "      <td>526929.00000</td>\n",
       "      <td>6758510.5</td>\n",
       "      <td>-1366.930908</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.756483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.799348</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769125</th>\n",
       "      <td>34/10-21</td>\n",
       "      <td>1628.562403</td>\n",
       "      <td>454132.37500</td>\n",
       "      <td>6777261.5</td>\n",
       "      <td>-1599.359131</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>Utsira Fm.</td>\n",
       "      <td>19.285599</td>\n",
       "      <td>0.543060</td>\n",
       "      <td>0.642111</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.545550</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275536</th>\n",
       "      <td>25/2-7</td>\n",
       "      <td>2099.122001</td>\n",
       "      <td>479878.09375</td>\n",
       "      <td>6641112.0</td>\n",
       "      <td>-2073.992188</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>Frigg Fm.</td>\n",
       "      <td>18.266001</td>\n",
       "      <td>0.418746</td>\n",
       "      <td>0.418746</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616284</th>\n",
       "      <td>31/3-2</td>\n",
       "      <td>919.488901</td>\n",
       "      <td>536839.50000</td>\n",
       "      <td>6748637.0</td>\n",
       "      <td>-894.453125</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.946561</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100417</th>\n",
       "      <td>16/11-1 ST3</td>\n",
       "      <td>1122.193201</td>\n",
       "      <td>474567.84375</td>\n",
       "      <td>6436487.0</td>\n",
       "      <td>-1095.178955</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.713800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.143502</td>\n",
       "      <td>...</td>\n",
       "      <td>8.649863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421248</th>\n",
       "      <td>25/8-5 S</td>\n",
       "      <td>3054.702400</td>\n",
       "      <td>464181.93750</td>\n",
       "      <td>6590501.0</td>\n",
       "      <td>-2696.029297</td>\n",
       "      <td>DUNLIN GP.</td>\n",
       "      <td>Statfjord Fm.</td>\n",
       "      <td>8.800037</td>\n",
       "      <td>0.488769</td>\n",
       "      <td>0.536209</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461741</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.300038</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.413952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.526392</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14616</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>2716.768000</td>\n",
       "      <td>437613.40625</td>\n",
       "      <td>6470982.5</td>\n",
       "      <td>-2691.347168</td>\n",
       "      <td>CROMER KNOLL GP.</td>\n",
       "      <td>Aasgard Fm.</td>\n",
       "      <td>9.453100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.295451</td>\n",
       "      <td>...</td>\n",
       "      <td>3.699115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016948</td>\n",
       "      <td>0.144990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381034</th>\n",
       "      <td>25/6-3</td>\n",
       "      <td>1852.355729</td>\n",
       "      <td>495724.37500</td>\n",
       "      <td>6618260.0</td>\n",
       "      <td>-1826.705688</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>Skade Fm.</td>\n",
       "      <td>9.325887</td>\n",
       "      <td>0.668839</td>\n",
       "      <td>0.770673</td>\n",
       "      <td>...</td>\n",
       "      <td>11.608711</td>\n",
       "      <td>475.488983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.153378</td>\n",
       "      <td>0.659583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                WELL     DEPTH_MD         X_LOC      Y_LOC        Z_LOC  \\\n",
       "1050250      35/11-7  1717.270000  531919.12500  6766800.0 -1688.224243   \n",
       "1011558     35/11-12  2604.402000  520565.84375  6777349.0 -2580.281006   \n",
       "578123        31/2-8  1391.996979  526929.00000  6758510.5 -1366.930908   \n",
       "769125      34/10-21  1628.562403  454132.37500  6777261.5 -1599.359131   \n",
       "275536        25/2-7  2099.122001  479878.09375  6641112.0 -2073.992188   \n",
       "616284        31/3-2   919.488901  536839.50000  6748637.0  -894.453125   \n",
       "100417   16/11-1 ST3  1122.193201  474567.84375  6436487.0 -1095.178955   \n",
       "421248      25/8-5 S  3054.702400  464181.93750  6590501.0 -2696.029297   \n",
       "14616        15/9-13  2716.768000  437613.40625  6470982.5 -2691.347168   \n",
       "381034        25/6-3  1852.355729  495724.37500  6618260.0 -1826.705688   \n",
       "\n",
       "                    GROUP      FORMATION       CALI      RSHA      RMED  ...  \\\n",
       "1050250      ROGALAND GP.      Vaale Fm.  13.276628       NaN  1.865714  ...   \n",
       "1011558      SHETLAND GP.      Kyrre Fm.        NaN       NaN  1.120980  ...   \n",
       "578123      HORDALAND GP.            NaN  18.756483       NaN  0.799348  ...   \n",
       "769125      HORDALAND GP.     Utsira Fm.  19.285599  0.543060  0.642111  ...   \n",
       "275536      HORDALAND GP.      Frigg Fm.  18.266001  0.418746  0.418746  ...   \n",
       "616284      HORDALAND GP.            NaN        NaN       NaN  0.946561  ...   \n",
       "100417      HORDALAND GP.            NaN  12.713800       NaN  1.143502  ...   \n",
       "421248         DUNLIN GP.  Statfjord Fm.   8.800037  0.488769  0.536209  ...   \n",
       "14616    CROMER KNOLL GP.    Aasgard Fm.   9.453100       NaN  2.295451  ...   \n",
       "381034      HORDALAND GP.      Skade Fm.   9.325887  0.668839  0.770673  ...   \n",
       "\n",
       "               ROP         DTS      DCAL      DRHO  MUDWEIGHT      RMIC  ROPA  \\\n",
       "1050250        NaN         NaN       NaN  0.057762        NaN       NaN   NaN   \n",
       "1011558  32.112389         NaN       NaN       NaN        NaN       NaN   NaN   \n",
       "578123         NaN         NaN       NaN  0.027651        NaN       NaN   NaN   \n",
       "769125         NaN         NaN       NaN  0.003044        NaN       NaN   NaN   \n",
       "275536         NaN         NaN       NaN -0.021000        NaN       NaN   NaN   \n",
       "616284         NaN         NaN       NaN  0.009480        NaN       NaN   NaN   \n",
       "100417    8.649863         NaN       NaN       NaN        NaN       NaN   NaN   \n",
       "421248    1.461741         NaN  0.300038  0.004100   1.413952       NaN   NaN   \n",
       "14616     3.699115         NaN       NaN -0.016948   0.144990       NaN   NaN   \n",
       "381034   11.608711  475.488983       NaN       NaN   0.153378  0.659583   NaN   \n",
       "\n",
       "              RXO  FORCE_2020_LITHOFACIES_LITHOLOGY  \\\n",
       "1050250       NaN                             70000   \n",
       "1011558       NaN                             65000   \n",
       "578123        NaN                             65000   \n",
       "769125   0.545550                             65000   \n",
       "275536        NaN                             30000   \n",
       "616284        NaN                             65000   \n",
       "100417        NaN                             65000   \n",
       "421248   0.526392                             30000   \n",
       "14616         NaN                             80000   \n",
       "381034        NaN                             65000   \n",
       "\n",
       "         FORCE_2020_LITHOFACIES_CONFIDENCE  \n",
       "1050250                                1.0  \n",
       "1011558                                2.0  \n",
       "578123                                 1.0  \n",
       "769125                                 1.0  \n",
       "275536                                 1.0  \n",
       "616284                                 1.0  \n",
       "100417                                 1.0  \n",
       "421248                                 1.0  \n",
       "14616                                  1.0  \n",
       "381034                                 1.0  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1170511, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WELL', 'DEPTH_MD', 'X_LOC', 'Y_LOC', 'Z_LOC', 'GROUP', 'FORMATION',\n",
       "       'CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'SGR', 'NPHI', 'PEF',\n",
       "       'DTC', 'SP', 'BS', 'ROP', 'DTS', 'DCAL', 'DRHO', 'MUDWEIGHT', 'RMIC',\n",
       "       'ROPA', 'RXO', 'FORCE_2020_LITHOFACIES_LITHOLOGY',\n",
       "       'FORCE_2020_LITHOFACIES_CONFIDENCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab target and map it to scoring matrix index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lith_codes = df['FORCE_2020_LITHOFACIES_LITHOLOGY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lith_ordinal = lith_codes.map(LITHOLOGY_ORDINAL_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop target column\n",
    "This should be done outside the preprocess method. This way, we can preprocess both train and test set with the same method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('FORCE_2020_LITHOFACIES_LITHOLOGY', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop columns with uncommon logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of missing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGR                                  0.940750\n",
       "DTS                                  0.850823\n",
       "RMIC                                 0.849502\n",
       "ROPA                                 0.835691\n",
       "DCAL                                 0.744699\n",
       "MUDWEIGHT                            0.729903\n",
       "RXO                                  0.720270\n",
       "ROP                                  0.542874\n",
       "RSHA                                 0.461218\n",
       "PEF                                  0.426155\n",
       "BS                                   0.416787\n",
       "NPHI                                 0.346090\n",
       "SP                                   0.261650\n",
       "DRHO                                 0.156046\n",
       "RHOB                                 0.137777\n",
       "FORMATION                            0.117038\n",
       "CALI                                 0.075076\n",
       "DTC                                  0.069084\n",
       "RMED                                 0.033313\n",
       "RDEP                                 0.009410\n",
       "Z_LOC                                0.009205\n",
       "Y_LOC                                0.009205\n",
       "X_LOC                                0.009205\n",
       "GROUP                                0.001092\n",
       "FORCE_2020_LITHOFACIES_CONFIDENCE    0.000153\n",
       "DEPTH_MD                             0.000000\n",
       "GR                                   0.000000\n",
       "WELL                                 0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = (df.isna().sum() / df.shape[0]).sort_values(ascending=False)\n",
    "\n",
    "print('Percent of missing values')\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list we can see that there are a few logs with high rate of missing values. Let's drop those with more than 50% missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SGR', 'DTS', 'RMIC', 'ROPA', 'DCAL', 'MUDWEIGHT', 'RXO', 'ROP']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_cutoff = 0.5\n",
    "cols = missing_values[missing_values > missing_value_cutoff].index.to_list()\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drop columns in the competition winner code are:\n",
    "\n",
    "| Drop column |\n",
    "| ----------- |\n",
    "|FORCE_2020_LITHOFACIES_CONFIDENCE|\n",
    "|SGR|\n",
    "|DTS|\n",
    "|RXO|\n",
    "|ROPA|\n",
    "\n",
    "There is some overlap with the columns found using the 50% cutoff on the missing values. The main discrepancy is the column `FORCE_2020_LITHOFACIES_CONFIDENCE`. This column is meant to assing a certainty value (ordinal) to the lithology interpretation. However, it will not be present in the prediction data (test) and thus it can't be used directly in the training. I'll drop it here, but it will be interesting to explore how to use it during training in future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.append('FORCE_2020_LITHOFACIES_CONFIDENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1170511, 19)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WELL          object\n",
       "DEPTH_MD     float64\n",
       "X_LOC        float64\n",
       "Y_LOC        float64\n",
       "Z_LOC        float64\n",
       "GROUP         object\n",
       "FORMATION     object\n",
       "CALI         float64\n",
       "RSHA         float64\n",
       "RMED         float64\n",
       "RDEP         float64\n",
       "RHOB         float64\n",
       "GR           float64\n",
       "NPHI         float64\n",
       "PEF          float64\n",
       "DTC          float64\n",
       "SP           float64\n",
       "BS           float64\n",
       "DRHO         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WELL', 'GROUP', 'FORMATION'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cat_columns = df.select_dtypes(include='object').columns\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The well name column `WELL` is important for referencing the sample but should not carry information about the lithologies it contains. Let's not encode it.\n",
    "\n",
    "Also, the `GROUP` and `FORMATION` columns could carry a lot of information about the target lithology, however, including these in the model could make it less robust for application in areas where these formations and groups don't exists (e.g. a different basin) or are named differently. In this case, I will encode them trying to stay close to Olawale's work, but in the future I'd like to test the effect of droppoing these columns in the model's score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['GROUP', 'FORMATION'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cat_columns = cat_columns.drop('WELL')\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GROUP</th>\n",
       "      <th>FORMATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GROUP FORMATION\n",
       "0  NORDLAND GP.       NaN\n",
       "1  NORDLAND GP.       NaN\n",
       "2  NORDLAND GP.       NaN\n",
       "3  NORDLAND GP.       NaN\n",
       "4  NORDLAND GP.       NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = df.loc[:, cat_columns]\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cat['GROUP'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HORDALAND GP.       0.250450\n",
       "SHETLAND GP.        0.199937\n",
       "VIKING GP.          0.112770\n",
       "ROGALAND GP.        0.112723\n",
       "DUNLIN GP.          0.101738\n",
       "NORDLAND GP.        0.095249\n",
       "CROMER KNOLL GP.    0.044698\n",
       "BAAT GP.            0.030605\n",
       "VESTLAND GP.        0.022312\n",
       "HEGRE GP.           0.011886\n",
       "ZECHSTEIN GP.       0.010455\n",
       "BOKNFJORD GP.       0.002670\n",
       "ROTLIEGENDES GP.    0.002385\n",
       "NaN                 0.001092\n",
       "TYNE GP.            0.001029\n",
       "Name: GROUP, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['GROUP'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent of missing values in GROUP is: 0.1092%\n"
     ]
    }
   ],
   "source": [
    "group_missing_perc = df_cat['GROUP'].isna().sum() / len(df_cat['GROUP'])\n",
    "\n",
    "print(f'The percent of missing values in GROUP is: {group_missing_perc*100:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formation missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cat['FORMATION'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Utsira Fm.               0.147488\n",
       "NaN                      0.117038\n",
       "Kyrre Fm.                0.080587\n",
       "Lista Fm.                0.060726\n",
       "Heather Fm.              0.055566\n",
       "                           ...   \n",
       "Broom Fm.                0.000201\n",
       "Intra Balder Fm. Sst.    0.000151\n",
       "Farsund Fm.              0.000146\n",
       "Flekkefjord Fm.          0.000101\n",
       "Egersund Fm.             0.000090\n",
       "Name: FORMATION, Length: 70, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['FORMATION'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent of missing values in GROUP is: 11.7038%\n"
     ]
    }
   ],
   "source": [
    "formation_missing_perc = df_cat['FORMATION'].isna().sum() / len(df_cat['FORMATION'])\n",
    "print(f'The percent of missing values in GROUP is: {formation_missing_perc*100:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encode\n",
    "The competition winner uses a label encoder in pandas. Since the model is tree-based and there is high cardinality in the formation column (70 unique categories), this is a reasonable compromise. Later, we could try to use one hot encoding to test the effect in the model score.\n",
    "\n",
    "Also, Olawale approach used -1 to mark missing values. In this case, I'll use numpy.nan instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NORDLAND GP.': 0,\n",
       " 'HORDALAND GP.': 1,\n",
       " 'ROGALAND GP.': 2,\n",
       " 'SHETLAND GP.': 3,\n",
       " 'CROMER KNOLL GP.': 4,\n",
       " 'VIKING GP.': 5,\n",
       " 'VESTLAND GP.': 6,\n",
       " 'ZECHSTEIN GP.': 7,\n",
       " 'HEGRE GP.': 8,\n",
       " 'ROTLIEGENDES GP.': 9,\n",
       " 'TYNE GP.': 10,\n",
       " 'BOKNFJORD GP.': 11,\n",
       " 'DUNLIN GP.': 12,\n",
       " 'BAAT GP.': 13}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_mapping = build_encoding_map(df_cat['GROUP'])\n",
    "group_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Utsira Fm.': 1,\n",
       " 'Balder Fm.': 2,\n",
       " 'Sele Fm.': 3,\n",
       " 'Lista Fm.': 4,\n",
       " 'Heimdal Fm.': 5,\n",
       " 'Tor Fm.': 6,\n",
       " 'Hod Fm.': 7,\n",
       " 'Blodoeks Fm.': 8,\n",
       " 'Svarte Fm.': 9,\n",
       " 'Roedby Fm.': 10,\n",
       " 'Sola Fm.': 11,\n",
       " 'Aasgard Fm.': 12,\n",
       " 'Draupne Fm.': 13,\n",
       " 'Heather Fm.': 14,\n",
       " 'Hugin Fm.': 15,\n",
       " 'Smith Bank Fm.': 16,\n",
       " 'Frigg Fm.': 17,\n",
       " 'Skagerrak Fm.': 18,\n",
       " 'Ekofisk Fm.': 19,\n",
       " 'Kupferschiefer Fm.': 20,\n",
       " 'Skade Fm.': 21,\n",
       " 'Grid Fm.': 22,\n",
       " 'Vaale Fm.': 23,\n",
       " 'Sleipner Fm.': 24,\n",
       " 'Hidra Fm.': 25,\n",
       " 'Tuxen Fm.': 26,\n",
       " 'Mandal Fm.': 27,\n",
       " 'Ula Fm.': 28,\n",
       " 'Bryne Fm.': 29,\n",
       " 'Tau Fm.': 30,\n",
       " 'Sandnes Fm.': 31,\n",
       " 'Intra Draupne Fm. Sst.': 32,\n",
       " 'Statfjord Fm.': 33,\n",
       " 'Skade Mb.': 34,\n",
       " 'BASEMENT': 35,\n",
       " 'Ran Sst Mb.': 36,\n",
       " 'Flekkefjord Fm.': 37,\n",
       " 'Sauda Fm.': 38,\n",
       " 'Egersund Fm.': 39,\n",
       " 'Intra Balder Fm. Sst.': 40,\n",
       " 'Hermod Mb.': 41,\n",
       " 'Ty Fm.': 42,\n",
       " 'Hardraade Fm.': 43,\n",
       " 'Kyrre Fm.': 44,\n",
       " 'Tryggvason Fm.': 45,\n",
       " 'Drake Fm.': 46,\n",
       " 'Cook Fm.': 47,\n",
       " 'Amundsen Fm.': 48,\n",
       " 'Grid Mb.': 49,\n",
       " 'Ty Mb.': 50,\n",
       " 'Jorsalfare Fm.': 51,\n",
       " 'Burton Fm.': 52,\n",
       " 'Mime Fm.': 53,\n",
       " 'Intra Heather Fm. Sst.': 54,\n",
       " 'Tarbert Fm.': 55,\n",
       " 'Ness Fm.': 56,\n",
       " 'Etive Fm.': 57,\n",
       " 'Rannoch Fm.': 58,\n",
       " 'Broom Fm.': 59,\n",
       " 'Lunde Fm.': 60,\n",
       " 'Oseberg Fm.': 61,\n",
       " 'Sognefjord Fm.': 62,\n",
       " 'Fensfjord Fm.': 63,\n",
       " 'Krossfjord Fm.': 64,\n",
       " 'Johansen Fm.': 65,\n",
       " 'Eiriksson Mb.': 66,\n",
       " 'Raude Mb.': 67,\n",
       " 'Agat Fm.': 68,\n",
       " 'Farsund Fm.': 69}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formation_mapping = build_encoding_map(df_cat['FORMATION'])\n",
    "formation_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {col: build_encoding_map(df_cat[col]) for col in df_cat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded, encoded_col_names = label_encode_columns(df, cat_columns, mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WELL</th>\n",
       "      <th>DEPTH_MD</th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>Z_LOC</th>\n",
       "      <th>CALI</th>\n",
       "      <th>RSHA</th>\n",
       "      <th>RMED</th>\n",
       "      <th>RDEP</th>\n",
       "      <th>RHOB</th>\n",
       "      <th>GR</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>PEF</th>\n",
       "      <th>DTC</th>\n",
       "      <th>SP</th>\n",
       "      <th>BS</th>\n",
       "      <th>DRHO</th>\n",
       "      <th>GROUP_encoded</th>\n",
       "      <th>FORMATION_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.528</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.501831</td>\n",
       "      <td>19.480835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.611410</td>\n",
       "      <td>1.798681</td>\n",
       "      <td>1.884186</td>\n",
       "      <td>80.200851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.915468</td>\n",
       "      <td>161.131180</td>\n",
       "      <td>24.612379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.574928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.680</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.653809</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.618070</td>\n",
       "      <td>1.795641</td>\n",
       "      <td>1.889794</td>\n",
       "      <td>79.262886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.383013</td>\n",
       "      <td>160.603470</td>\n",
       "      <td>23.895531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.570188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.832</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.805786</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.626459</td>\n",
       "      <td>1.800733</td>\n",
       "      <td>1.896523</td>\n",
       "      <td>74.821999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.591518</td>\n",
       "      <td>160.173615</td>\n",
       "      <td>23.916357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.574245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.984</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.957794</td>\n",
       "      <td>19.459282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.621594</td>\n",
       "      <td>1.801517</td>\n",
       "      <td>1.891913</td>\n",
       "      <td>72.878922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.191910</td>\n",
       "      <td>160.149429</td>\n",
       "      <td>23.793688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.586315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>495.136</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-470.109772</td>\n",
       "      <td>19.453100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.602679</td>\n",
       "      <td>1.795299</td>\n",
       "      <td>1.880034</td>\n",
       "      <td>71.729141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.495632</td>\n",
       "      <td>160.128342</td>\n",
       "      <td>24.104078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.597914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WELL  DEPTH_MD         X_LOC      Y_LOC       Z_LOC       CALI  RSHA  \\\n",
       "0  15/9-13   494.528  437641.96875  6470972.5 -469.501831  19.480835   NaN   \n",
       "1  15/9-13   494.680  437641.96875  6470972.5 -469.653809  19.468800   NaN   \n",
       "2  15/9-13   494.832  437641.96875  6470972.5 -469.805786  19.468800   NaN   \n",
       "3  15/9-13   494.984  437641.96875  6470972.5 -469.957794  19.459282   NaN   \n",
       "4  15/9-13   495.136  437641.96875  6470972.5 -470.109772  19.453100   NaN   \n",
       "\n",
       "       RMED      RDEP      RHOB         GR  NPHI        PEF         DTC  \\\n",
       "0  1.611410  1.798681  1.884186  80.200851   NaN  20.915468  161.131180   \n",
       "1  1.618070  1.795641  1.889794  79.262886   NaN  19.383013  160.603470   \n",
       "2  1.626459  1.800733  1.896523  74.821999   NaN  22.591518  160.173615   \n",
       "3  1.621594  1.801517  1.891913  72.878922   NaN  32.191910  160.149429   \n",
       "4  1.602679  1.795299  1.880034  71.729141   NaN  38.495632  160.128342   \n",
       "\n",
       "          SP  BS      DRHO  GROUP_encoded  FORMATION_encoded  \n",
       "0  24.612379 NaN -0.574928            0.0                NaN  \n",
       "1  23.895531 NaN -0.570188            0.0                NaN  \n",
       "2  23.916357 NaN -0.574245            0.0                NaN  \n",
       "3  23.793688 NaN -0.586315            0.0                NaN  \n",
       "4  24.104078 NaN -0.597914            0.0                NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute missing values\n",
    "In the winning code, the missing values are filled with three different values:\n",
    "\n",
    "1. -999: For missing values in the raw logs.\n",
    "2. 0: This is used in Bestagini's feature augmentation to fill missing values created by these functions.\n",
    "3. -1: This is use in the encoding of the categorical columns.\n",
    "\n",
    "In my case, I'll use numpy.nan for these three cases. Since XGboost can handle missing data, I think it is an acceptable first pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment features usign Bestagini's functions.\n",
    "In notebook 4.0, I explore Bestagini's functions originally written using numpy, and compare them to my pandas version. Here, I incorporate my pandas version of these functions to the preprocess method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocesed = shift_concat_gradient(df_encoded,\n",
    "                                       'DEPTH_MD',\n",
    "                                       'WELL',\n",
    "                                       encoded_col_names,\n",
    "                                       periods=1,\n",
    "                                       fill_value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_LOC_shifted_1</th>\n",
       "      <th>Y_LOC_shifted_1</th>\n",
       "      <th>Z_LOC_shifted_1</th>\n",
       "      <th>CALI_shifted_1</th>\n",
       "      <th>RSHA_shifted_1</th>\n",
       "      <th>RMED_shifted_1</th>\n",
       "      <th>RDEP_shifted_1</th>\n",
       "      <th>RHOB_shifted_1</th>\n",
       "      <th>GR_shifted_1</th>\n",
       "      <th>NPHI_shifted_1</th>\n",
       "      <th>...</th>\n",
       "      <th>RMED_gradient</th>\n",
       "      <th>RDEP_gradient</th>\n",
       "      <th>RHOB_gradient</th>\n",
       "      <th>GR_gradient</th>\n",
       "      <th>NPHI_gradient</th>\n",
       "      <th>PEF_gradient</th>\n",
       "      <th>DTC_gradient</th>\n",
       "      <th>SP_gradient</th>\n",
       "      <th>BS_gradient</th>\n",
       "      <th>DRHO_gradient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.501831</td>\n",
       "      <td>19.480835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.611410</td>\n",
       "      <td>1.798681</td>\n",
       "      <td>1.884186</td>\n",
       "      <td>80.200851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043819</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>0.036893</td>\n",
       "      <td>-6.170825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.081944</td>\n",
       "      <td>-3.471776</td>\n",
       "      <td>-4.716108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.653809</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.618070</td>\n",
       "      <td>1.795641</td>\n",
       "      <td>1.889794</td>\n",
       "      <td>79.262886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055186</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.044271</td>\n",
       "      <td>-29.216365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.108590</td>\n",
       "      <td>-2.827996</td>\n",
       "      <td>0.137015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.026689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.805786</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.626459</td>\n",
       "      <td>1.800733</td>\n",
       "      <td>1.896523</td>\n",
       "      <td>74.821999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032003</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>-0.030329</td>\n",
       "      <td>-12.783402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.160470</td>\n",
       "      <td>-0.159113</td>\n",
       "      <td>-0.807034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.079409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.957794</td>\n",
       "      <td>19.459282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.621594</td>\n",
       "      <td>1.801517</td>\n",
       "      <td>1.891913</td>\n",
       "      <td>72.878922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124441</td>\n",
       "      <td>-0.040905</td>\n",
       "      <td>-0.078150</td>\n",
       "      <td>-7.564344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.471858</td>\n",
       "      <td>-0.138735</td>\n",
       "      <td>2.042043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.076305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_LOC_shifted_1  Y_LOC_shifted_1  Z_LOC_shifted_1  CALI_shifted_1  \\\n",
       "0              NaN              NaN              NaN             NaN   \n",
       "1     437641.96875        6470972.5      -469.501831       19.480835   \n",
       "2     437641.96875        6470972.5      -469.653809       19.468800   \n",
       "3     437641.96875        6470972.5      -469.805786       19.468800   \n",
       "4     437641.96875        6470972.5      -469.957794       19.459282   \n",
       "\n",
       "   RSHA_shifted_1  RMED_shifted_1  RDEP_shifted_1  RHOB_shifted_1  \\\n",
       "0             NaN             NaN             NaN             NaN   \n",
       "1             NaN        1.611410        1.798681        1.884186   \n",
       "2             NaN        1.618070        1.795641        1.889794   \n",
       "3             NaN        1.626459        1.800733        1.896523   \n",
       "4             NaN        1.621594        1.801517        1.891913   \n",
       "\n",
       "   GR_shifted_1  NPHI_shifted_1  ...  RMED_gradient  RDEP_gradient  \\\n",
       "0           NaN             NaN  ...            NaN            NaN   \n",
       "1     80.200851             NaN  ...       0.043819      -0.020000   \n",
       "2     79.262886             NaN  ...       0.055186       0.033500   \n",
       "3     74.821999             NaN  ...      -0.032003       0.005153   \n",
       "4     72.878922             NaN  ...      -0.124441      -0.040905   \n",
       "\n",
       "   RHOB_gradient  GR_gradient  NPHI_gradient  PEF_gradient  DTC_gradient  \\\n",
       "0            NaN          NaN            NaN           NaN           NaN   \n",
       "1       0.036893    -6.170825            NaN    -10.081944     -3.471776   \n",
       "2       0.044271   -29.216365            NaN     21.108590     -2.827996   \n",
       "3      -0.030329   -12.783402            NaN     63.160470     -0.159113   \n",
       "4      -0.078150    -7.564344            NaN     41.471858     -0.138735   \n",
       "\n",
       "   SP_gradient  BS_gradient  DRHO_gradient  \n",
       "0          NaN          NaN            NaN  \n",
       "1    -4.716108          NaN       0.031179  \n",
       "2     0.137015          NaN      -0.026689  \n",
       "3    -0.807034          NaN      -0.079409  \n",
       "4     2.042043          NaN      -0.076305  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocesed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1170511, 68)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocesed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X_LOC_shifted_1                float64\n",
       "Y_LOC_shifted_1                float64\n",
       "Z_LOC_shifted_1                float64\n",
       "CALI_shifted_1                 float64\n",
       "RSHA_shifted_1                 float64\n",
       "RMED_shifted_1                 float64\n",
       "RDEP_shifted_1                 float64\n",
       "RHOB_shifted_1                 float64\n",
       "GR_shifted_1                   float64\n",
       "NPHI_shifted_1                 float64\n",
       "PEF_shifted_1                  float64\n",
       "DTC_shifted_1                  float64\n",
       "SP_shifted_1                   float64\n",
       "BS_shifted_1                   float64\n",
       "DRHO_shifted_1                 float64\n",
       "GROUP_encoded_shifted_1        float64\n",
       "FORMATION_encoded_shifted_1    float64\n",
       "X_LOC                          float64\n",
       "Y_LOC                          float64\n",
       "Z_LOC                          float64\n",
       "CALI                           float64\n",
       "RSHA                           float64\n",
       "RMED                           float64\n",
       "RDEP                           float64\n",
       "RHOB                           float64\n",
       "GR                             float64\n",
       "NPHI                           float64\n",
       "PEF                            float64\n",
       "DTC                            float64\n",
       "SP                             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocesed.dtypes.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BS                              float64\n",
       "DRHO                            float64\n",
       "GROUP_encoded                   float64\n",
       "FORMATION_encoded               float64\n",
       "X_LOC_shifted_-1                float64\n",
       "Y_LOC_shifted_-1                float64\n",
       "Z_LOC_shifted_-1                float64\n",
       "CALI_shifted_-1                 float64\n",
       "RSHA_shifted_-1                 float64\n",
       "RMED_shifted_-1                 float64\n",
       "RDEP_shifted_-1                 float64\n",
       "RHOB_shifted_-1                 float64\n",
       "GR_shifted_-1                   float64\n",
       "NPHI_shifted_-1                 float64\n",
       "PEF_shifted_-1                  float64\n",
       "DTC_shifted_-1                  float64\n",
       "SP_shifted_-1                   float64\n",
       "BS_shifted_-1                   float64\n",
       "DRHO_shifted_-1                 float64\n",
       "GROUP_encoded_shifted_-1        float64\n",
       "FORMATION_encoded_shifted_-1    float64\n",
       "WELL                             object\n",
       "DEPTH_MD                        float64\n",
       "X_LOC_gradient                  float64\n",
       "Y_LOC_gradient                  float64\n",
       "Z_LOC_gradient                  float64\n",
       "CALI_gradient                   float64\n",
       "RSHA_gradient                   float64\n",
       "RMED_gradient                   float64\n",
       "RDEP_gradient                   float64\n",
       "RHOB_gradient                   float64\n",
       "GR_gradient                     float64\n",
       "NPHI_gradient                   float64\n",
       "PEF_gradient                    float64\n",
       "DTC_gradient                    float64\n",
       "SP_gradient                     float64\n",
       "BS_gradient                     float64\n",
       "DRHO_gradient                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocesed.dtypes.tail(38)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lith_pred",
   "language": "python",
   "name": "lith_pred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
