{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.definitions import ROOT_DIR, LITHOLOGY_ORDINAL_MAP\n",
    "from src.features.build_features import replace_nan_inf, shift_concat, gradient, shift_concat_gradient\n",
    "from src.features.build_features import build_encoding_map, label_encode_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Olawale preprocess\n",
    "\n",
    "The competition winner employs the following steps to preprocess the data:\n",
    "\n",
    "\n",
    "1. Grab target and map it to scoring matrix index (lithology_ordinal).\n",
    "\n",
    "2. Drop columns with uncommon logs.\n",
    "\n",
    "3. Encode Group, Formation, and Well names. In my opinion, we should drop the well names before training.\n",
    "\n",
    "4. Fill mising values with -999. I think XGBoost can handle missing values. Alternatively, we could use a fancier imputation method.\n",
    "\n",
    "5. Drop target column.\n",
    "\n",
    "6. Augment features usign Bestagini's functions.\n",
    "\n",
    "7. Return augmented features and lithology ordinal\n",
    "\n",
    "In this notebook I explore each step, before wrinting the resulting strategy as a `preprocess` method in the `Model` class. Also, Olawale preprocessed the train and test data in the same method. I'd like to create the preprocess method for the train set, and then apply it to both train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = ROOT_DIR / 'data/external' / 'CSV_train.csv'\n",
    "\n",
    "assert train_path.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_path, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WELL</th>\n",
       "      <th>DEPTH_MD</th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>Z_LOC</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>FORMATION</th>\n",
       "      <th>CALI</th>\n",
       "      <th>RSHA</th>\n",
       "      <th>RMED</th>\n",
       "      <th>...</th>\n",
       "      <th>ROP</th>\n",
       "      <th>DTS</th>\n",
       "      <th>DCAL</th>\n",
       "      <th>DRHO</th>\n",
       "      <th>MUDWEIGHT</th>\n",
       "      <th>RMIC</th>\n",
       "      <th>ROPA</th>\n",
       "      <th>RXO</th>\n",
       "      <th>FORCE_2020_LITHOFACIES_LITHOLOGY</th>\n",
       "      <th>FORCE_2020_LITHOFACIES_CONFIDENCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233075</th>\n",
       "      <td>25/2-13 T4</td>\n",
       "      <td>1748.624000</td>\n",
       "      <td>469388.43750</td>\n",
       "      <td>6628718.0</td>\n",
       "      <td>-1724.982178</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>Utsira Fm.</td>\n",
       "      <td>17.722181</td>\n",
       "      <td>0.686670</td>\n",
       "      <td>0.640484</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.222181</td>\n",
       "      <td>0.052007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093621</th>\n",
       "      <td>35/4-1</td>\n",
       "      <td>4441.484000</td>\n",
       "      <td>516154.09375</td>\n",
       "      <td>6822429.5</td>\n",
       "      <td>-4411.997070</td>\n",
       "      <td>DUNLIN GP.</td>\n",
       "      <td>Cook Fm.</td>\n",
       "      <td>8.841048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.014909</td>\n",
       "      <td>...</td>\n",
       "      <td>7.346700</td>\n",
       "      <td>143.865829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65030</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941738</th>\n",
       "      <td>34/8-1</td>\n",
       "      <td>3557.673023</td>\n",
       "      <td>469634.46875</td>\n",
       "      <td>6803982.5</td>\n",
       "      <td>-3503.131348</td>\n",
       "      <td>HEGRE GP.</td>\n",
       "      <td>Lunde Fm.</td>\n",
       "      <td>9.296900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.394699</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160348</th>\n",
       "      <td>7/1-1</td>\n",
       "      <td>1568.248800</td>\n",
       "      <td>450391.65625</td>\n",
       "      <td>6406643.5</td>\n",
       "      <td>-1534.206177</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.514511</td>\n",
       "      <td>0.706342</td>\n",
       "      <td>0.712185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.014511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.473865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196504</th>\n",
       "      <td>17/11-1</td>\n",
       "      <td>889.153016</td>\n",
       "      <td>520153.18750</td>\n",
       "      <td>6452287.5</td>\n",
       "      <td>-862.153015</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.854943</td>\n",
       "      <td>0.579711</td>\n",
       "      <td>1.380905</td>\n",
       "      <td>...</td>\n",
       "      <td>367.187469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060447</td>\n",
       "      <td>1.090420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425366</th>\n",
       "      <td>25/8-7</td>\n",
       "      <td>1297.599115</td>\n",
       "      <td>475895.84375</td>\n",
       "      <td>6593126.5</td>\n",
       "      <td>-1272.599121</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>Skade Fm.</td>\n",
       "      <td>12.327062</td>\n",
       "      <td>0.440568</td>\n",
       "      <td>0.442160</td>\n",
       "      <td>...</td>\n",
       "      <td>125.334198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152180</td>\n",
       "      <td>0.289885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126396</th>\n",
       "      <td>16/2-16</td>\n",
       "      <td>1174.166396</td>\n",
       "      <td>476768.15625</td>\n",
       "      <td>6523588.5</td>\n",
       "      <td>-1147.801636</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>Skade Fm.</td>\n",
       "      <td>13.202827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878562</td>\n",
       "      <td>...</td>\n",
       "      <td>31.119102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795477</th>\n",
       "      <td>34/10-35</td>\n",
       "      <td>1761.007000</td>\n",
       "      <td>463380.62500</td>\n",
       "      <td>6771052.5</td>\n",
       "      <td>-1737.873901</td>\n",
       "      <td>HORDALAND GP.</td>\n",
       "      <td>Utsira Fm.</td>\n",
       "      <td>17.053471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661962</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65030</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539894</th>\n",
       "      <td>31/2-1</td>\n",
       "      <td>1240.852200</td>\n",
       "      <td>530202.31250</td>\n",
       "      <td>6737678.5</td>\n",
       "      <td>-1216.825806</td>\n",
       "      <td>ROGALAND GP.</td>\n",
       "      <td>Balder Fm.</td>\n",
       "      <td>17.562464</td>\n",
       "      <td>1.247392</td>\n",
       "      <td>1.247392</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516970</th>\n",
       "      <td>30/3-5 S</td>\n",
       "      <td>4441.409586</td>\n",
       "      <td>497012.56250</td>\n",
       "      <td>6739994.5</td>\n",
       "      <td>-3143.267578</td>\n",
       "      <td>DUNLIN GP.</td>\n",
       "      <td>Cook Fm.</td>\n",
       "      <td>8.697601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.870127</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               WELL     DEPTH_MD         X_LOC      Y_LOC        Z_LOC  \\\n",
       "233075   25/2-13 T4  1748.624000  469388.43750  6628718.0 -1724.982178   \n",
       "1093621      35/4-1  4441.484000  516154.09375  6822429.5 -4411.997070   \n",
       "941738       34/8-1  3557.673023  469634.46875  6803982.5 -3503.131348   \n",
       "1160348       7/1-1  1568.248800  450391.65625  6406643.5 -1534.206177   \n",
       "196504      17/11-1   889.153016  520153.18750  6452287.5  -862.153015   \n",
       "425366       25/8-7  1297.599115  475895.84375  6593126.5 -1272.599121   \n",
       "126396      16/2-16  1174.166396  476768.15625  6523588.5 -1147.801636   \n",
       "795477     34/10-35  1761.007000  463380.62500  6771052.5 -1737.873901   \n",
       "539894       31/2-1  1240.852200  530202.31250  6737678.5 -1216.825806   \n",
       "516970     30/3-5 S  4441.409586  497012.56250  6739994.5 -3143.267578   \n",
       "\n",
       "                 GROUP   FORMATION       CALI      RSHA      RMED  ...  \\\n",
       "233075   HORDALAND GP.  Utsira Fm.  17.722181  0.686670  0.640484  ...   \n",
       "1093621     DUNLIN GP.    Cook Fm.   8.841048       NaN  5.014909  ...   \n",
       "941738       HEGRE GP.   Lunde Fm.   9.296900       NaN  4.394699  ...   \n",
       "1160348  HORDALAND GP.         NaN  18.514511  0.706342  0.712185  ...   \n",
       "196504   HORDALAND GP.         NaN  12.854943  0.579711  1.380905  ...   \n",
       "425366   HORDALAND GP.   Skade Fm.  12.327062  0.440568  0.442160  ...   \n",
       "126396   HORDALAND GP.   Skade Fm.  13.202827       NaN  0.878562  ...   \n",
       "795477   HORDALAND GP.  Utsira Fm.  17.053471       NaN  0.661962  ...   \n",
       "539894    ROGALAND GP.  Balder Fm.  17.562464  1.247392  1.247392  ...   \n",
       "516970      DUNLIN GP.    Cook Fm.   8.697601       NaN  5.870127  ...   \n",
       "\n",
       "                ROP         DTS      DCAL      DRHO  MUDWEIGHT      RMIC  \\\n",
       "233075          NaN         NaN  0.222181  0.052007        NaN       NaN   \n",
       "1093621    7.346700  143.865829       NaN  0.002783        NaN       NaN   \n",
       "941738          NaN         NaN       NaN -0.016090        NaN       NaN   \n",
       "1160348    0.915075         NaN  1.014511       NaN   1.473865       NaN   \n",
       "196504   367.187469         NaN       NaN  0.060447   1.090420       NaN   \n",
       "425366   125.334198         NaN  0.077061       NaN   0.152180  0.289885   \n",
       "126396    31.119102         NaN       NaN  0.008583        NaN       NaN   \n",
       "795477          NaN         NaN       NaN -0.018579        NaN       NaN   \n",
       "539894          NaN         NaN       NaN  0.003456        NaN       NaN   \n",
       "516970          NaN         NaN       NaN  0.009312        NaN       NaN   \n",
       "\n",
       "         ROPA  RXO  FORCE_2020_LITHOFACIES_LITHOLOGY  \\\n",
       "233075    NaN  NaN                             65000   \n",
       "1093621   NaN  NaN                             65030   \n",
       "941738    NaN  NaN                             65000   \n",
       "1160348   NaN  NaN                             65000   \n",
       "196504    NaN  NaN                             65000   \n",
       "425366    NaN  NaN                             30000   \n",
       "126396    NaN  NaN                             65000   \n",
       "795477    NaN  NaN                             65030   \n",
       "539894    NaN  NaN                             99000   \n",
       "516970    NaN  NaN                             30000   \n",
       "\n",
       "         FORCE_2020_LITHOFACIES_CONFIDENCE  \n",
       "233075                                 1.0  \n",
       "1093621                                1.0  \n",
       "941738                                 1.0  \n",
       "1160348                                1.0  \n",
       "196504                                 1.0  \n",
       "425366                                 1.0  \n",
       "126396                                 1.0  \n",
       "795477                                 1.0  \n",
       "539894                                 3.0  \n",
       "516970                                 1.0  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1170511, 29)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WELL', 'DEPTH_MD', 'X_LOC', 'Y_LOC', 'Z_LOC', 'GROUP', 'FORMATION',\n",
       "       'CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'SGR', 'NPHI', 'PEF',\n",
       "       'DTC', 'SP', 'BS', 'ROP', 'DTS', 'DCAL', 'DRHO', 'MUDWEIGHT', 'RMIC',\n",
       "       'ROPA', 'RXO', 'FORCE_2020_LITHOFACIES_LITHOLOGY',\n",
       "       'FORCE_2020_LITHOFACIES_CONFIDENCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grab target and map it to scoring matrix index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lith_codes = df['FORCE_2020_LITHOFACIES_LITHOLOGY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lith_ordinal = lith_codes.map(LITHOLOGY_ORDINAL_MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop target column\n",
    "This should be done outside the preprocess method. This way, we can preprocess both train and test set with the same method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('FORCE_2020_LITHOFACIES_LITHOLOGY', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop columns with uncommon logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of missing values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGR                                  0.940750\n",
       "DTS                                  0.850823\n",
       "RMIC                                 0.849502\n",
       "ROPA                                 0.835691\n",
       "DCAL                                 0.744699\n",
       "MUDWEIGHT                            0.729903\n",
       "RXO                                  0.720270\n",
       "ROP                                  0.542874\n",
       "RSHA                                 0.461218\n",
       "PEF                                  0.426155\n",
       "BS                                   0.416787\n",
       "NPHI                                 0.346090\n",
       "SP                                   0.261650\n",
       "DRHO                                 0.156046\n",
       "RHOB                                 0.137777\n",
       "FORMATION                            0.117038\n",
       "CALI                                 0.075076\n",
       "DTC                                  0.069084\n",
       "RMED                                 0.033313\n",
       "RDEP                                 0.009410\n",
       "Z_LOC                                0.009205\n",
       "Y_LOC                                0.009205\n",
       "X_LOC                                0.009205\n",
       "GROUP                                0.001092\n",
       "FORCE_2020_LITHOFACIES_CONFIDENCE    0.000153\n",
       "DEPTH_MD                             0.000000\n",
       "GR                                   0.000000\n",
       "WELL                                 0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = (df.isna().sum() / df.shape[0]).sort_values(ascending=False)\n",
    "\n",
    "print('Percent of missing values')\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list we can see that there are a few logs with high rate of missing values. Let's drop those with more than 50% missing values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SGR', 'DTS', 'RMIC', 'ROPA', 'DCAL', 'MUDWEIGHT', 'RXO', 'ROP']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_value_cutoff = 0.5\n",
    "cols = missing_values[missing_values > missing_value_cutoff].index.to_list()\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drop columns in the competition winner code are:\n",
    "\n",
    "| Drop column |\n",
    "| ----------- |\n",
    "|FORCE_2020_LITHOFACIES_CONFIDENCE|\n",
    "|SGR|\n",
    "|DTS|\n",
    "|RXO|\n",
    "|ROPA|\n",
    "\n",
    "There is some overlap with the columns found using the 50% cutoff on the missing values. The main discrepancy is the column `FORCE_2020_LITHOFACIES_CONFIDENCE`. This column is meant to assing a certainty value (ordinal) to the lithology interpretation. However, it will not be present in the prediction data (test) and thus it can't be used directly in the training. I'll drop it here, but it will be interesting to explore how to use it during training in future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.append('FORCE_2020_LITHOFACIES_CONFIDENCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1170511, 19)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WELL          object\n",
       "DEPTH_MD     float64\n",
       "X_LOC        float64\n",
       "Y_LOC        float64\n",
       "Z_LOC        float64\n",
       "GROUP         object\n",
       "FORMATION     object\n",
       "CALI         float64\n",
       "RSHA         float64\n",
       "RMED         float64\n",
       "RDEP         float64\n",
       "RHOB         float64\n",
       "GR           float64\n",
       "NPHI         float64\n",
       "PEF          float64\n",
       "DTC          float64\n",
       "SP           float64\n",
       "BS           float64\n",
       "DRHO         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WELL', 'GROUP', 'FORMATION'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cat_columns = df.select_dtypes(include='object').columns\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The well name column `WELL` is important for referencing the sample but should not carry information about the lithologies it contains. Let's not encode it.\n",
    "\n",
    "Also, the `GROUP` and `FORMATION` columns could carry a lot of information about the target lithology, however, including these in the model could make it less robust for application in areas where these formations and groups don't exists (e.g. a different basin) or are named differently. In this case, I will encode them trying to stay close to Olawale's work, but in the future I'd like to test the effect of droppoing these columns in the model's score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['GROUP', 'FORMATION'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "cat_columns = cat_columns.drop('WELL')\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GROUP</th>\n",
       "      <th>FORMATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NORDLAND GP.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GROUP FORMATION\n",
       "0  NORDLAND GP.       NaN\n",
       "1  NORDLAND GP.       NaN\n",
       "2  NORDLAND GP.       NaN\n",
       "3  NORDLAND GP.       NaN\n",
       "4  NORDLAND GP.       NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat = df.loc[:, cat_columns]\n",
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cat['GROUP'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HORDALAND GP.       0.250450\n",
       "SHETLAND GP.        0.199937\n",
       "VIKING GP.          0.112770\n",
       "ROGALAND GP.        0.112723\n",
       "DUNLIN GP.          0.101738\n",
       "NORDLAND GP.        0.095249\n",
       "CROMER KNOLL GP.    0.044698\n",
       "BAAT GP.            0.030605\n",
       "VESTLAND GP.        0.022312\n",
       "HEGRE GP.           0.011886\n",
       "ZECHSTEIN GP.       0.010455\n",
       "BOKNFJORD GP.       0.002670\n",
       "ROTLIEGENDES GP.    0.002385\n",
       "NaN                 0.001092\n",
       "TYNE GP.            0.001029\n",
       "Name: GROUP, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['GROUP'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent of missing values in GROUP is: 0.1092%\n"
     ]
    }
   ],
   "source": [
    "group_missing_perc = df_cat['GROUP'].isna().sum() / len(df_cat['GROUP'])\n",
    "\n",
    "print(f'The percent of missing values in GROUP is: {group_missing_perc*100:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formation missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_cat['FORMATION'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Utsira Fm.               0.147488\n",
       "NaN                      0.117038\n",
       "Kyrre Fm.                0.080587\n",
       "Lista Fm.                0.060726\n",
       "Heather Fm.              0.055566\n",
       "                           ...   \n",
       "Broom Fm.                0.000201\n",
       "Intra Balder Fm. Sst.    0.000151\n",
       "Farsund Fm.              0.000146\n",
       "Flekkefjord Fm.          0.000101\n",
       "Egersund Fm.             0.000090\n",
       "Name: FORMATION, Length: 70, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat['FORMATION'].value_counts(normalize=True, dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percent of missing values in GROUP is: 11.7038%\n"
     ]
    }
   ],
   "source": [
    "formation_missing_perc = df_cat['FORMATION'].isna().sum() / len(df_cat['FORMATION'])\n",
    "print(f'The percent of missing values in GROUP is: {formation_missing_perc*100:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encode\n",
    "The competition winner uses a label encoder in pandas. Since the model is tree-based and there is high cardinality in the formation column (70 unique categories), this is a reasonable compromise. Later, we could try to use one hot encoding to test the effect in the model score.\n",
    "\n",
    "Also, Olawale approach used -1 to mark missing values. In this case, I'll use numpy.nan instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NORDLAND GP.': 0,\n",
       " 'HORDALAND GP.': 1,\n",
       " 'ROGALAND GP.': 2,\n",
       " 'SHETLAND GP.': 3,\n",
       " 'CROMER KNOLL GP.': 4,\n",
       " 'VIKING GP.': 5,\n",
       " 'VESTLAND GP.': 6,\n",
       " 'ZECHSTEIN GP.': 7,\n",
       " 'HEGRE GP.': 8,\n",
       " 'ROTLIEGENDES GP.': 9,\n",
       " 'TYNE GP.': 10,\n",
       " 'BOKNFJORD GP.': 11,\n",
       " 'DUNLIN GP.': 12,\n",
       " 'BAAT GP.': 13}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_mapping = build_encoding_map(df_cat['GROUP'])\n",
    "group_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Utsira Fm.': 1,\n",
       " 'Balder Fm.': 2,\n",
       " 'Sele Fm.': 3,\n",
       " 'Lista Fm.': 4,\n",
       " 'Heimdal Fm.': 5,\n",
       " 'Tor Fm.': 6,\n",
       " 'Hod Fm.': 7,\n",
       " 'Blodoeks Fm.': 8,\n",
       " 'Svarte Fm.': 9,\n",
       " 'Roedby Fm.': 10,\n",
       " 'Sola Fm.': 11,\n",
       " 'Aasgard Fm.': 12,\n",
       " 'Draupne Fm.': 13,\n",
       " 'Heather Fm.': 14,\n",
       " 'Hugin Fm.': 15,\n",
       " 'Smith Bank Fm.': 16,\n",
       " 'Frigg Fm.': 17,\n",
       " 'Skagerrak Fm.': 18,\n",
       " 'Ekofisk Fm.': 19,\n",
       " 'Kupferschiefer Fm.': 20,\n",
       " 'Skade Fm.': 21,\n",
       " 'Grid Fm.': 22,\n",
       " 'Vaale Fm.': 23,\n",
       " 'Sleipner Fm.': 24,\n",
       " 'Hidra Fm.': 25,\n",
       " 'Tuxen Fm.': 26,\n",
       " 'Mandal Fm.': 27,\n",
       " 'Ula Fm.': 28,\n",
       " 'Bryne Fm.': 29,\n",
       " 'Tau Fm.': 30,\n",
       " 'Sandnes Fm.': 31,\n",
       " 'Intra Draupne Fm. Sst.': 32,\n",
       " 'Statfjord Fm.': 33,\n",
       " 'Skade Mb.': 34,\n",
       " 'BASEMENT': 35,\n",
       " 'Ran Sst Mb.': 36,\n",
       " 'Flekkefjord Fm.': 37,\n",
       " 'Sauda Fm.': 38,\n",
       " 'Egersund Fm.': 39,\n",
       " 'Intra Balder Fm. Sst.': 40,\n",
       " 'Hermod Mb.': 41,\n",
       " 'Ty Fm.': 42,\n",
       " 'Hardraade Fm.': 43,\n",
       " 'Kyrre Fm.': 44,\n",
       " 'Tryggvason Fm.': 45,\n",
       " 'Drake Fm.': 46,\n",
       " 'Cook Fm.': 47,\n",
       " 'Amundsen Fm.': 48,\n",
       " 'Grid Mb.': 49,\n",
       " 'Ty Mb.': 50,\n",
       " 'Jorsalfare Fm.': 51,\n",
       " 'Burton Fm.': 52,\n",
       " 'Mime Fm.': 53,\n",
       " 'Intra Heather Fm. Sst.': 54,\n",
       " 'Tarbert Fm.': 55,\n",
       " 'Ness Fm.': 56,\n",
       " 'Etive Fm.': 57,\n",
       " 'Rannoch Fm.': 58,\n",
       " 'Broom Fm.': 59,\n",
       " 'Lunde Fm.': 60,\n",
       " 'Oseberg Fm.': 61,\n",
       " 'Sognefjord Fm.': 62,\n",
       " 'Fensfjord Fm.': 63,\n",
       " 'Krossfjord Fm.': 64,\n",
       " 'Johansen Fm.': 65,\n",
       " 'Eiriksson Mb.': 66,\n",
       " 'Raude Mb.': 67,\n",
       " 'Agat Fm.': 68,\n",
       " 'Farsund Fm.': 69}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formation_mapping = build_encoding_map(df_cat['FORMATION'])\n",
    "formation_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = {col: build_encoding_map(df_cat[col]) for col in df_cat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded, encoded_col_names = label_encode_columns(df, cat_columns, mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WELL</th>\n",
       "      <th>DEPTH_MD</th>\n",
       "      <th>X_LOC</th>\n",
       "      <th>Y_LOC</th>\n",
       "      <th>Z_LOC</th>\n",
       "      <th>CALI</th>\n",
       "      <th>RSHA</th>\n",
       "      <th>RMED</th>\n",
       "      <th>RDEP</th>\n",
       "      <th>RHOB</th>\n",
       "      <th>GR</th>\n",
       "      <th>NPHI</th>\n",
       "      <th>PEF</th>\n",
       "      <th>DTC</th>\n",
       "      <th>SP</th>\n",
       "      <th>BS</th>\n",
       "      <th>DRHO</th>\n",
       "      <th>GROUP_encoded</th>\n",
       "      <th>FORMATION_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.528</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.501831</td>\n",
       "      <td>19.480835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.611410</td>\n",
       "      <td>1.798681</td>\n",
       "      <td>1.884186</td>\n",
       "      <td>80.200851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.915468</td>\n",
       "      <td>161.131180</td>\n",
       "      <td>24.612379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.574928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.680</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.653809</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.618070</td>\n",
       "      <td>1.795641</td>\n",
       "      <td>1.889794</td>\n",
       "      <td>79.262886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.383013</td>\n",
       "      <td>160.603470</td>\n",
       "      <td>23.895531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.570188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.832</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.805786</td>\n",
       "      <td>19.468800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.626459</td>\n",
       "      <td>1.800733</td>\n",
       "      <td>1.896523</td>\n",
       "      <td>74.821999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.591518</td>\n",
       "      <td>160.173615</td>\n",
       "      <td>23.916357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.574245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>494.984</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-469.957794</td>\n",
       "      <td>19.459282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.621594</td>\n",
       "      <td>1.801517</td>\n",
       "      <td>1.891913</td>\n",
       "      <td>72.878922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.191910</td>\n",
       "      <td>160.149429</td>\n",
       "      <td>23.793688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.586315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15/9-13</td>\n",
       "      <td>495.136</td>\n",
       "      <td>437641.96875</td>\n",
       "      <td>6470972.5</td>\n",
       "      <td>-470.109772</td>\n",
       "      <td>19.453100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.602679</td>\n",
       "      <td>1.795299</td>\n",
       "      <td>1.880034</td>\n",
       "      <td>71.729141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.495632</td>\n",
       "      <td>160.128342</td>\n",
       "      <td>24.104078</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.597914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      WELL  DEPTH_MD         X_LOC      Y_LOC       Z_LOC       CALI  RSHA  \\\n",
       "0  15/9-13   494.528  437641.96875  6470972.5 -469.501831  19.480835   NaN   \n",
       "1  15/9-13   494.680  437641.96875  6470972.5 -469.653809  19.468800   NaN   \n",
       "2  15/9-13   494.832  437641.96875  6470972.5 -469.805786  19.468800   NaN   \n",
       "3  15/9-13   494.984  437641.96875  6470972.5 -469.957794  19.459282   NaN   \n",
       "4  15/9-13   495.136  437641.96875  6470972.5 -470.109772  19.453100   NaN   \n",
       "\n",
       "       RMED      RDEP      RHOB         GR  NPHI        PEF         DTC  \\\n",
       "0  1.611410  1.798681  1.884186  80.200851   NaN  20.915468  161.131180   \n",
       "1  1.618070  1.795641  1.889794  79.262886   NaN  19.383013  160.603470   \n",
       "2  1.626459  1.800733  1.896523  74.821999   NaN  22.591518  160.173615   \n",
       "3  1.621594  1.801517  1.891913  72.878922   NaN  32.191910  160.149429   \n",
       "4  1.602679  1.795299  1.880034  71.729141   NaN  38.495632  160.128342   \n",
       "\n",
       "          SP  BS      DRHO  GROUP_encoded  FORMATION_encoded  \n",
       "0  24.612379 NaN -0.574928            0.0                NaN  \n",
       "1  23.895531 NaN -0.570188            0.0                NaN  \n",
       "2  23.916357 NaN -0.574245            0.0                NaN  \n",
       "3  23.793688 NaN -0.586315            0.0                NaN  \n",
       "4  24.104078 NaN -0.597914            0.0                NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute missing values\n",
    "In the winning code, the missing values are filled with three different values:\n",
    "\n",
    "1. -999: For missing values in the raw logs.\n",
    "2. 0: This is used in Bestagini's feature augmentation to fill missing values created by these functions.\n",
    "3. -1: This is use in the encoding of the categorical columns.\n",
    "\n",
    "In my case, I'll use numpy.nan for these three cases. Since XGboost can handle missing data, I think it is an acceptable first pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment features usign Bestagini's functions.\n",
    "In notebook 4.0, I explore Bestagini's functions originally written using numpy, and compare them to my pandas version. Here, I incorporate my pandas version of these functions to the preprocess method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocesed = shift_concat_gradient(df_encoded, 'DEPTH_MD', 'WELL', periods=1, fill_value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocesed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocesed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocesed.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lith_pred",
   "language": "python",
   "name": "lith_pred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
