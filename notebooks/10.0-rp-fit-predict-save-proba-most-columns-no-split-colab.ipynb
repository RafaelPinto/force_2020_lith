{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10.0-rp-fit-predict-save-proba-most-columns-no-split-colab.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"cells":[{"cell_type":"code","metadata":{"id":"I2sl9W3Au1hZ","executionInfo":{"status":"ok","timestamp":1612645563299,"user_tz":360,"elapsed":1115,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["from pathlib import Path\n","import pickle\n","\n","import numpy as np\n","import numpy.random as nr\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import pandas as pd\n","\n","import sklearn\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import preprocessing\n","import sklearn.model_selection as ms\n","from sklearn.model_selection import StratifiedKFold, train_test_split\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","import xgboost as xgb\n","from xgboost import XGBClassifier"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QyMvK7e8u1hg","executionInfo":{"status":"ok","timestamp":1612645564151,"user_tz":360,"elapsed":320,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}},"outputId":"35316c7e-e61f-4636-9e08-eea1a994ec7e"},"source":["# Print out packages versions\n","print(f'pandas version is: {pd.__version__}')\n","print(f'numpy version is: {np.__version__}')\n","print(f'matplotlib version is: {matplotlib.__version__}')\n","print(f'sklearn version is: {sklearn.__version__}')\n","print(f'xgboost version is: {xgb.__version__}')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["pandas version is: 1.1.5\n","numpy version is: 1.19.5\n","matplotlib version is: 3.2.2\n","sklearn version is: 0.22.2.post1\n","xgboost version is: 0.90\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HE9_Q2bsu1hi"},"source":["# Helper functions"]},{"cell_type":"code","metadata":{"id":"m1x1Oo6ju1hi","executionInfo":{"status":"ok","timestamp":1612645565830,"user_tz":360,"elapsed":345,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["def replace_nan_inf(df, value=None):\n","    \"\"\"\n","    Replace missing and infinity values.\n","\n","    Parameters\n","    ----------\n","    df : pandas.DataFrame\n","        Dataframe with values to be replaced.\n","\n","    value : int, float\n","        Value to replace any missing or numpy.inf values. Defaults to numpy.nan\n","    Returns\n","    -------\n","    pandas.DataFrame\n","        Dataframe with missing and infinity values replaced with -999.\n","\n","    \"\"\"\n","    if value is None:\n","        value = np.nan\n","    return df.replace(to_replace=[np.nan, np.inf, -np.inf],\n","                      value=value)\n","\n","\n","def shift_concat(df, periods=1, fill_value=None):\n","    \"\"\"\n","    Build dataframe of shifted index.\n","\n","    Parameters\n","    ----------\n","    df : pandas.DataFrame\n","        Dataframe with columns to be shifted.\n","    periods : int\n","        Number of periods to shift. Should be positive.\n","    fill_value : object, optional\n","        The scalar value to use for newly introduced missing values. Defaults\n","        to numpy.nan.\n","\n","    Returns\n","    -------\n","    pandas.DataFrame\n","        Shifted dataframes concatenated along columns axis.\n","\n","    Notes\n","    -------\n","    Based on Paulo Bestagini's augment_features_window from SEG 2016 ML\n","    competition.\n","    https://github.com/seg/2016-ml-contest/blob/master/ispl/facies_classification_try01.ipynb\n","\n","    Example\n","    -------\n","    Shift df by one period and concatenate.\n","\n","    >>> df = pd.DataFrame({'gr': [1.1, 2.1], 'den': [2.1, 2.2]})\n","    >>> shift_concat(df)\n","        gr_shifted_1  den_shifted_1  gr   den  gr_shifted_-1   den_shifted_-1\n","    0      NaN            NaN        1.1  2.1      2.1             2.2\n","    1      1.1            2.1        2.1  2.2      NaN             NaN\n","\n","    \"\"\"\n","    if fill_value is None:\n","        fill_value = np.nan\n","\n","    dfs = []\n","    for period in range(periods, -1*periods - 1, -1):\n","\n","        if period == 0:\n","            dfs.append(df)\n","            continue\n","\n","        df_shifted = df.shift(period, fill_value=fill_value)\n","\n","        df_shifted.columns = [f'{col}_shifted_{str(period)}'\n","                              for col in df_shifted.columns]\n","\n","        dfs.append(df_shifted)\n","\n","    return pd.concat(dfs, axis=1)\n","\n","\n","def gradient(df, depth_col):\n","    \"\"\"\n","    Calculate the gradient for all features along the provided `depth_col`\n","    column.\n","\n","    Parameters\n","    ----------\n","    df : pandas.DataFrame\n","        Dataframe with columns to be used in the gradient calculation.\n","    depth_col : str\n","        Dataframe column name to be used as depth reference.\n","\n","    Returns\n","    -------\n","    pandas.DataFrame\n","        Gradient of `df` along `depth_col` column. The depth column is not in\n","        the output dataframe.\n","\n","    Notes\n","    -------\n","    Based on Paulo Bestagini's augment_features_window from SEG 2016 ML\n","    competition.\n","    https://github.com/seg/2016-ml-contest/blob/master/ispl/facies_classification_try01.ipynb\n","\n","    Example\n","    -------\n","    Calculate gradient of columns along `md`.\n","\n","    >>> df = pd.DataFrame({'gr': [100.1, 100.2, 100.3],\n","                          'den': [2.1, 2.2, 2.3],\n","                          'md': [500, 500.5, 501]})\n","    >>> gradient(df, 'md')\n","        gr  den\n","    0  NaN  NaN\n","    1  0.2  0.2\n","    2  0.2  0.2\n","\n","    \"\"\"\n","    depth_diff = df[depth_col].diff()\n","\n","    denom_zeros = np.isclose(depth_diff, 0)\n","    depth_diff[denom_zeros] = 0.001\n","\n","    df_diff = df.drop(depth_col, axis=1)\n","    df_diff = df_diff.diff()\n","\n","    # Add suffix to column names\n","    df_diff.columns = [f'{col}_gradient' for col in df_diff.columns]\n","\n","    return df_diff.divide(depth_diff, axis=0)\n","\n","\n","def shift_concat_gradient(df, depth_col, well_col, cat_cols, periods=1, fill_value=None):\n","    \"\"\"\n","    Augment features using `shif_concat` and `gradient`.\n","\n","    Parameters\n","    ----------\n","    df : pandas.DataFrame\n","        Dataframe with columns to be augmented.\n","    depth_col : str\n","        Dataframe column name to be used as depth reference.\n","    well_col : str\n","        Dataframe column name to be used as well reference.\n","    cat_cols: list of str\n","        Encoded column names. The gradient calculation is not applied to these\n","        columns.\n","    periods : int\n","        Number of periods to shift. Should be positive.\n","    fill_value : object, optional\n","        The scalar value to use for newly introduced missing values. Defaults\n","        to numpy.nan.\n","\n","    Returns\n","    -------\n","    pandas.DataFrame\n","        Augmented dataframe.\n","\n","    Notes\n","    -------\n","    Based on Paulo Bestagini's augment_features_window from SEG 2016 ML\n","    competition.\n","    https://github.com/seg/2016-ml-contest/blob/master/ispl/facies_classification_try01.ipynb\n","\n","    Example\n","    -------\n","    Augment features of `df` by shifting and taking the gradient.\n","\n","    >>> df = pd.DataFrame({'gr': [100.1, 100.2, 100.3, 20.1, 20.2, 20.3],\n","                          'den': [2.1, 2.2, 2.3, 1.7, 1.8, 1.9],\n","                           'md': [500, 500.5, 501, 1000, 1000.05, 1001],\n","                         'well': [1, 1, 1, 2, 2, 2]})\n","    >>> shift_concat_gradient(df, 'md', 'well', periods=1, fill_value=None)\n","        gr_shifted_1  den_shifted_1     gr    den  ...  well   md    gr_gradient  den_gradient\n","    0         NaN          NaN         100.1  2.1  ...   1   500.00        NaN           NaN\n","    1       100.1          2.1         100.2  2.2  ...   1   500.50   0.200000      0.200000\n","    2       100.2          2.2         100.3  2.3  ...   1   501.00   0.200000      0.200000\n","    3         NaN          NaN          20.1  1.7  ...   2  1000.00        NaN           NaN\n","    4        20.1          1.7          20.2  1.8  ...   2  1000.05   2.000000      2.000000\n","    5        20.2          1.8          20.3  1.9  ...   2  1001.00   0.105263      0.105263\n","\n","    \"\"\"\n","    # TODO 'Consider filling missing values created here with DataFrame.fillna'\n","\n","    # Columns to apply gradient operation\n","    cat_cols.append(well_col)\n","    gradient_cols = [col for col in df.columns if col not in cat_cols]\n","\n","    # Don't shift depth\n","    depth = df.loc[:, depth_col]\n","\n","    grouped = df.groupby(well_col, sort=False)\n","\n","    df_aug_groups = []\n","    for name, group in grouped:\n","        shift_cols_df = group.drop([well_col, depth_col], axis=1)\n","\n","        group_shift = shift_concat(shift_cols_df,\n","                                   periods=periods,\n","                                   fill_value=fill_value)\n","\n","        # Add back the well name and depth\n","        group_shift[well_col] = name\n","        group_shift[depth_col] = depth\n","\n","        group_gradient = group.loc[:, gradient_cols]\n","\n","        group_gradient = gradient(group_gradient, depth_col)\n","\n","        group_aug = pd.concat([group_shift, group_gradient], axis=1)\n","\n","        df_aug_groups.append(group_aug)\n","\n","    return pd.concat(df_aug_groups)\n","\n","\n","def score(y_true, y_pred, scoring_matrix):\n","    \"\"\"\n","    Competition scoring function.\n","\n","    Parameters\n","    ----------\n","    y_true : pandas.Series\n","        Ground truth (correct) target values.\n","    y_pred : pandas.Series\n","        Estimated targets as returned by a classifier.\n","    scoring_matrix : numpy.array\n","        Competition scoring matrix.\n","\n","    Returns\n","    ----------\n","    float\n","        2020 FORCE ML lithology competition custome score.\n","\n","    \"\"\"\n","    S = 0.0\n","\n","    for true_val, pred_val in zip(y_true, y_pred):\n","        S -= scoring_matrix[true_val, pred_val]\n","\n","    return S/y_true.shape[0]\n","\n","\n","def show_evaluation(y_true, y_pred):\n","    \"\"\"\n","    Print model performance and evaluation.\n","\n","    Parameters\n","    ----------\n","    y_true : pandas.Series\n","        Ground truth (correct) target values.\n","    y_pred: pandas.Series\n","        Estimated targets as returned by a classifier.\n","\n","    \"\"\"\n","    print(f'Competition score: {score(y_true, y_pred)}')\n","    print(f'Accuracy: {accuracy_score(y_true, y_pred)}')\n","    print(f'F1: {f1_score(y_true, y_pred, average=\"weighted\")}')\n","\n","\n","def build_encoding_map(series):\n","    \"\"\"\n","    Build dictionary with the mapping of series unique values to encoded\n","    values.\n","\n","    Parameters\n","    ----------\n","    series : pandas.Series\n","        Series with categories to be encoded.\n","\n","    Returns\n","    -------\n","    mapping : dict\n","        Dictionary mapping unique categories in series to encoded values.\n","\n","    See Also\n","    --------\n","    label_encode_columns : Label encode a dataframe categorical columns.\n","\n","    \"\"\"\n","    unique_values = series.unique()\n","\n","    mapping = {original: encoded\n","               for encoded, original in enumerate(unique_values)\n","               if original is not np.nan}\n","\n","    return mapping\n","\n","\n","def label_encode_columns(df, cat_cols, mappings):\n","    \"\"\"\n","    Label encode a dataframe categorical columns.\n","\n","    Parameters\n","    ----------\n","    df : pandas.DataFrame\n","        Dataframe with columns to be encoded.\n","    cat_cols: list of str\n","        Column names to be encoded.\n","    mappings: dict of dict\n","        Dictionary containing a key-value mapping for each column to be\n","        encoded.\n","\n","    Returns\n","    -------\n","    df : pandas.DataFrame\n","        Dataframe with the encoded columns added and the `cat_cols` removed.\n","    encoded_col_names: list of str\n","        Encoded column names.\n","\n","    See Also\n","    --------\n","    build_encoding_map : Build a series encoding mapping.\n","\n","    \"\"\"\n","    df = df.copy()\n","\n","    encoded_col_names = []\n","    for col in cat_cols:\n","        new_col = f'{col}_encoded'\n","        encoded_col_names.append(new_col)\n","\n","        df[new_col] = df[col].map(mappings[col])\n","\n","        df.drop(col, axis=1, inplace=True)\n","\n","    return df, encoded_col_names"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b5S-CRBbGc02"},"source":["# Target maps"]},{"cell_type":"code","metadata":{"id":"pKPoKfl6Geev","executionInfo":{"status":"ok","timestamp":1612645567462,"user_tz":360,"elapsed":296,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["KEYS_TO_ORDINAL = {\n","    30000: 0,\n","    65030: 1,\n","    65000: 2,\n","    80000: 3,\n","    74000: 4,\n","    70000: 5,\n","    70032: 6,\n","    88000: 7,\n","    86000: 8,\n","    99000: 9,\n","    90000: 10,\n","    93000: 11\n","    }\n","\n","\n","KEYS_TO_LITHOLOGY = {30000: 'Sandstone',\n","                     65030: 'Sandstone/Shale',\n","                     65000: 'Shale',\n","                     80000: 'Marl',\n","                     74000: 'Dolomite',\n","                     70000: 'Limestone',\n","                     70032: 'Chalk',\n","                     88000: 'Halite',\n","                     86000: 'Anhydrite',\n","                     99000: 'Tuff',\n","                     90000: 'Coal',\n","                     93000: 'Basement'}\n","\n","ORDINAL_TO_KEYS = {value: key for key, value in  KEYS_TO_ORDINAL.items()}\n","\n","ORDINAL_TO_LITHOLOGY = {}\n","for ordinal_key, key in ORDINAL_TO_KEYS.items():\n","    ORDINAL_TO_LITHOLOGY[ordinal_key] = KEYS_TO_LITHOLOGY[key]"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V-_H1SeJu1ho"},"source":["# Import data\n","\n","First add a shortcut from the [google drive competition data location](https://drive.google.com/drive/folders/1GIkjq4fwgwbiqVQxYwoJnOJWVobZ91pL) to your own google drive. We will mount this drive, and access the data from it.\n","\n","We will save the results to a diffent folder, where we have write access."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fEYM1Xz2u1ht","executionInfo":{"status":"ok","timestamp":1612645587006,"user_tz":360,"elapsed":18510,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}},"outputId":"f19bd008-0bd0-42cb-84c3-277188dfc159"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RpIq9zscu1hu","executionInfo":{"status":"ok","timestamp":1612645590620,"user_tz":360,"elapsed":324,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["#should be edited to the present working directory of the user\n","data_source = '/content/drive/My Drive/FORCE 2020 lithofacies prediction from well logs competition/'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"7BG8lQNYu1hu","executionInfo":{"status":"ok","timestamp":1612645598900,"user_tz":360,"elapsed":7681,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["penalty_matrix = np.load(data_source + 'penalty_matrix.npy')\n","\n","train = pd.read_csv(data_source + 'CSV_train.csv', sep=';')\n","\n","test = pd.read_csv(data_source + 'CSV_test.csv', sep=';')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"dt2Oge4Fu1hv","executionInfo":{"status":"ok","timestamp":1612645598904,"user_tz":360,"elapsed":2150,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["# Destination folder\n","out_data_dir = Path('/content/drive/My Drive/lith_pred/')"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kJyhGrd8PDrK"},"source":["# Train model"]},{"cell_type":"code","metadata":{"id":"AmSp3xSsu1hv","executionInfo":{"status":"ok","timestamp":1612645601959,"user_tz":360,"elapsed":343,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["class Model():\n","    '''\n","    class to lithology prediction\n","    '''\n","    def preprocess(self, df, cat_columns, mappings):\n","        # Grab model features\n","        drop_cols = [\n","                     'FORCE_2020_LITHOFACIES_CONFIDENCE',\n","                     'SGR',\n","                     'DTS',\n","                     'RXO',\n","                     'ROPA'\n","                     ]\n","\n","        # Confirm drop columns are in df\n","        drop_cols = [col for col in drop_cols if col in df.columns]\n","\n","        df.drop(drop_cols, axis=1, inplace=True)\n","\n","        # Label encode\n","        df, encoded_col_names = label_encode_columns(df, cat_columns, mappings)\n","        \n","        # Augment using Bestagini's functions\n","        df_preprocesed = shift_concat_gradient(df,\n","                                               'DEPTH_MD',\n","                                               'WELL',\n","                                               encoded_col_names,\n","                                               periods=1,\n","                                               fill_value=None)\n","       \n","        return df_preprocesed\n","\n","    def fit(self, X, y):\n","        model = XGBClassifier(n_estimators=100, max_depth=10, booster='gbtree',\n","                              objective='multi:softprob', learning_rate=0.1, random_state=0,\n","                              subsample=0.9, colsample_bytree=0.9, tree_method='gpu_hist',\n","                              eval_metric='mlogloss', verbose=2020, reg_lambda=1500)\n","        \n","        X_train, X_test, y_train, y_test = train_test_split(X,\n","                                                            y,\n","                                                            test_size=0.33,\n","                                                            random_state=42,\n","                                                            shuffle=True,\n","                                                            stratify=y)\n","\n","        model.fit(X_train,\n","                  y_train,\n","                  early_stopping_rounds=100,\n","                  eval_set=[(X_test, y_test)],\n","                  verbose=100)\n","\n","        return model\n","\n","    def fit_predict(self, X_train, y_train, X_test, test_wells, save_filename):\n","        # Fit\n","        model = self.fit(X_train, y_train)\n","\n","        model_proba = model.predict_proba(X_test)\n","\n","        model_classes = [ORDINAL_TO_LITHOLOGY[lith] for lith in model.classes_]\n","\n","        model_proba_df = pd.DataFrame(model_proba, columns=model_classes)\n","\n","        model_proba_df['WELL'] = test_wells\n","        model_proba_df['DEPTH_MD'] = X_test['DEPTH_MD']\n","\n","        # Create save directory if it doesn't exists\n","        if not save_filename.parent.is_dir():\n","            save_filename.parent.mkdir(parents=True)\n","\n","        # Save models_proba to CSV\n","        model_proba_df.to_csv(save_filename, index=False)\n","\n","        return model, model_proba_df"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B0mFUwb2xlHl"},"source":["# Prepare train data"]},{"cell_type":"code","metadata":{"id":"HwneqeF3z1jO","executionInfo":{"status":"ok","timestamp":1612645606186,"user_tz":360,"elapsed":349,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["y = train['FORCE_2020_LITHOFACIES_LITHOLOGY']\n","X = train.drop('FORCE_2020_LITHOFACIES_LITHOLOGY', axis=1)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"zJCHVSlJA-co","executionInfo":{"status":"ok","timestamp":1612645606832,"user_tz":360,"elapsed":249,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["# Map lithology codes to scoring matrix index\n","y_train = y.map(KEYS_TO_ORDINAL)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"En8Qv66eu1hx","executionInfo":{"status":"ok","timestamp":1612645607566,"user_tz":360,"elapsed":255,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["model = Model()"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dNO2kMhXZ0AS","executionInfo":{"status":"ok","timestamp":1612645608556,"user_tz":360,"elapsed":409,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}},"outputId":"6db56e9c-ff7c-47a9-a058-ba64d302e0f7"},"source":["X.columns"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['WELL', 'DEPTH_MD', 'X_LOC', 'Y_LOC', 'Z_LOC', 'GROUP', 'FORMATION',\n","       'CALI', 'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'SGR', 'NPHI', 'PEF',\n","       'DTC', 'SP', 'BS', 'ROP', 'DTS', 'DCAL', 'DRHO', 'MUDWEIGHT', 'RMIC',\n","       'ROPA', 'RXO', 'FORCE_2020_LITHOFACIES_CONFIDENCE'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"5mELBxXDu1hx","executionInfo":{"status":"ok","timestamp":1612645613028,"user_tz":360,"elapsed":3808,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["cat_columns = ['GROUP', 'FORMATION']\n","\n","train_mappings = {col: build_encoding_map(X[col]) for col in cat_columns}\n","\n","X_train = model.preprocess(X, cat_columns, train_mappings)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJfgAoxISQzC","executionInfo":{"status":"ok","timestamp":1612645615011,"user_tz":360,"elapsed":955,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["X_train.drop('WELL', axis=1, inplace=True)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19DUYb8-fpb6","executionInfo":{"status":"ok","timestamp":1612645616099,"user_tz":360,"elapsed":213,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}},"outputId":"f76e0ec0-2d56-41fb-b235-1211c5dc3568"},"source":["X_train.columns"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['X_LOC_shifted_1', 'Y_LOC_shifted_1', 'Z_LOC_shifted_1',\n","       'CALI_shifted_1', 'RSHA_shifted_1', 'RMED_shifted_1', 'RDEP_shifted_1',\n","       'RHOB_shifted_1', 'GR_shifted_1', 'NPHI_shifted_1', 'PEF_shifted_1',\n","       'DTC_shifted_1', 'SP_shifted_1', 'BS_shifted_1', 'ROP_shifted_1',\n","       'DCAL_shifted_1', 'DRHO_shifted_1', 'MUDWEIGHT_shifted_1',\n","       'RMIC_shifted_1', 'GROUP_encoded_shifted_1',\n","       'FORMATION_encoded_shifted_1', 'X_LOC', 'Y_LOC', 'Z_LOC', 'CALI',\n","       'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'NPHI', 'PEF', 'DTC', 'SP', 'BS',\n","       'ROP', 'DCAL', 'DRHO', 'MUDWEIGHT', 'RMIC', 'GROUP_encoded',\n","       'FORMATION_encoded', 'X_LOC_shifted_-1', 'Y_LOC_shifted_-1',\n","       'Z_LOC_shifted_-1', 'CALI_shifted_-1', 'RSHA_shifted_-1',\n","       'RMED_shifted_-1', 'RDEP_shifted_-1', 'RHOB_shifted_-1',\n","       'GR_shifted_-1', 'NPHI_shifted_-1', 'PEF_shifted_-1', 'DTC_shifted_-1',\n","       'SP_shifted_-1', 'BS_shifted_-1', 'ROP_shifted_-1', 'DCAL_shifted_-1',\n","       'DRHO_shifted_-1', 'MUDWEIGHT_shifted_-1', 'RMIC_shifted_-1',\n","       'GROUP_encoded_shifted_-1', 'FORMATION_encoded_shifted_-1', 'DEPTH_MD',\n","       'X_LOC_gradient', 'Y_LOC_gradient', 'Z_LOC_gradient', 'CALI_gradient',\n","       'RSHA_gradient', 'RMED_gradient', 'RDEP_gradient', 'RHOB_gradient',\n","       'GR_gradient', 'NPHI_gradient', 'PEF_gradient', 'DTC_gradient',\n","       'SP_gradient', 'BS_gradient', 'ROP_gradient', 'DCAL_gradient',\n","       'DRHO_gradient', 'MUDWEIGHT_gradient', 'RMIC_gradient'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"zXA4OPsvxsFF"},"source":["# Prepare test data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xjs7KifMbJC1","executionInfo":{"status":"ok","timestamp":1612645619433,"user_tz":360,"elapsed":264,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}},"outputId":"c6f68585-4cca-43a4-b266-af5b21065563"},"source":["test.shape"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(136786, 27)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"S6h_L5weZOtA","executionInfo":{"status":"ok","timestamp":1612645620809,"user_tz":360,"elapsed":833,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["X_test = model.preprocess(test, cat_columns, train_mappings)\n","X_test.drop('WELL', axis=1, inplace=True)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BbvVEyfMb818","executionInfo":{"status":"ok","timestamp":1612645620942,"user_tz":360,"elapsed":310,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}},"outputId":"71eb7680-b13a-4867-cb2d-920589693e44"},"source":["X_test.shape"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(136786, 83)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDlqXc1oasD3","executionInfo":{"status":"ok","timestamp":1612645621787,"user_tz":360,"elapsed":286,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}},"outputId":"bb0f6f4a-066d-4e7b-9c83-573d7d194298"},"source":["X_test.columns"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['X_LOC_shifted_1', 'Y_LOC_shifted_1', 'Z_LOC_shifted_1',\n","       'CALI_shifted_1', 'RSHA_shifted_1', 'RMED_shifted_1', 'RDEP_shifted_1',\n","       'RHOB_shifted_1', 'GR_shifted_1', 'NPHI_shifted_1', 'PEF_shifted_1',\n","       'DTC_shifted_1', 'SP_shifted_1', 'BS_shifted_1', 'ROP_shifted_1',\n","       'DCAL_shifted_1', 'DRHO_shifted_1', 'MUDWEIGHT_shifted_1',\n","       'RMIC_shifted_1', 'GROUP_encoded_shifted_1',\n","       'FORMATION_encoded_shifted_1', 'X_LOC', 'Y_LOC', 'Z_LOC', 'CALI',\n","       'RSHA', 'RMED', 'RDEP', 'RHOB', 'GR', 'NPHI', 'PEF', 'DTC', 'SP', 'BS',\n","       'ROP', 'DCAL', 'DRHO', 'MUDWEIGHT', 'RMIC', 'GROUP_encoded',\n","       'FORMATION_encoded', 'X_LOC_shifted_-1', 'Y_LOC_shifted_-1',\n","       'Z_LOC_shifted_-1', 'CALI_shifted_-1', 'RSHA_shifted_-1',\n","       'RMED_shifted_-1', 'RDEP_shifted_-1', 'RHOB_shifted_-1',\n","       'GR_shifted_-1', 'NPHI_shifted_-1', 'PEF_shifted_-1', 'DTC_shifted_-1',\n","       'SP_shifted_-1', 'BS_shifted_-1', 'ROP_shifted_-1', 'DCAL_shifted_-1',\n","       'DRHO_shifted_-1', 'MUDWEIGHT_shifted_-1', 'RMIC_shifted_-1',\n","       'GROUP_encoded_shifted_-1', 'FORMATION_encoded_shifted_-1', 'DEPTH_MD',\n","       'X_LOC_gradient', 'Y_LOC_gradient', 'Z_LOC_gradient', 'CALI_gradient',\n","       'RSHA_gradient', 'RMED_gradient', 'RDEP_gradient', 'RHOB_gradient',\n","       'GR_gradient', 'NPHI_gradient', 'PEF_gradient', 'DTC_gradient',\n","       'SP_gradient', 'BS_gradient', 'ROP_gradient', 'DCAL_gradient',\n","       'DRHO_gradient', 'MUDWEIGHT_gradient', 'RMIC_gradient'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"FqwB9tmySP74"},"source":["# Fit and predict"]},{"cell_type":"code","metadata":{"id":"xwpDyV1fvpBs","executionInfo":{"status":"ok","timestamp":1612645625878,"user_tz":360,"elapsed":242,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["save_filename = out_data_dir / 'model_proba/models_proba_most_coulmns_with_nans_no_split.csv'"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"90mSTaF2qVo4","executionInfo":{"status":"ok","timestamp":1612645626764,"user_tz":360,"elapsed":267,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}}},"source":["test_wells = test['WELL']"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2fvmd_GqwVVk","executionInfo":{"status":"ok","timestamp":1612645690506,"user_tz":360,"elapsed":62573,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}},"outputId":"396bf566-3bf8-499c-c497-c5a8e20c797c"},"source":["if save_filename.is_file():\n","    models_proba = pd.read_csv(save_filename)\n","\n","else:\n","    model, model_proba = model.fit_predict(X_train, y_train, X_test, test_wells, save_filename)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["[0]\tvalidation_0-mlogloss:2.16529\n","Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n","[99]\tvalidation_0-mlogloss:0.329752\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JYmWcsrk1sBM"},"source":["# Explore models proba"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"KfKORh-avywY","executionInfo":{"status":"ok","timestamp":1612645712159,"user_tz":360,"elapsed":221,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}},"outputId":"4fa78604-7693-4291-8532-ddfe9952f433"},"source":["model_proba.sample(10)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sandstone</th>\n","      <th>Sandstone/Shale</th>\n","      <th>Shale</th>\n","      <th>Marl</th>\n","      <th>Dolomite</th>\n","      <th>Limestone</th>\n","      <th>Chalk</th>\n","      <th>Halite</th>\n","      <th>Anhydrite</th>\n","      <th>Tuff</th>\n","      <th>Coal</th>\n","      <th>Basement</th>\n","      <th>WELL</th>\n","      <th>DEPTH_MD</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>112406</th>\n","      <td>0.022301</td>\n","      <td>0.404550</td>\n","      <td>0.543959</td>\n","      <td>0.003627</td>\n","      <td>0.002058</td>\n","      <td>0.013062</td>\n","      <td>0.001477</td>\n","      <td>0.001320</td>\n","      <td>0.001317</td>\n","      <td>0.002676</td>\n","      <td>0.002420</td>\n","      <td>0.001235</td>\n","      <td>34/3-3 A</td>\n","      <td>4975.345976</td>\n","    </tr>\n","    <tr>\n","      <th>113793</th>\n","      <td>0.214400</td>\n","      <td>0.713408</td>\n","      <td>0.046524</td>\n","      <td>0.003014</td>\n","      <td>0.001749</td>\n","      <td>0.009322</td>\n","      <td>0.001255</td>\n","      <td>0.001122</td>\n","      <td>0.001119</td>\n","      <td>0.002274</td>\n","      <td>0.004763</td>\n","      <td>0.001049</td>\n","      <td>34/6-1 S</td>\n","      <td>3532.682400</td>\n","    </tr>\n","    <tr>\n","      <th>92619</th>\n","      <td>0.024301</td>\n","      <td>0.209458</td>\n","      <td>0.748701</td>\n","      <td>0.003029</td>\n","      <td>0.001678</td>\n","      <td>0.004439</td>\n","      <td>0.001294</td>\n","      <td>0.001156</td>\n","      <td>0.001153</td>\n","      <td>0.001458</td>\n","      <td>0.002252</td>\n","      <td>0.001081</td>\n","      <td>34/10-16 R</td>\n","      <td>3766.768008</td>\n","    </tr>\n","    <tr>\n","      <th>4725</th>\n","      <td>0.022312</td>\n","      <td>0.086483</td>\n","      <td>0.867751</td>\n","      <td>0.001933</td>\n","      <td>0.001964</td>\n","      <td>0.008154</td>\n","      <td>0.003016</td>\n","      <td>0.001022</td>\n","      <td>0.001020</td>\n","      <td>0.003192</td>\n","      <td>0.002199</td>\n","      <td>0.000956</td>\n","      <td>15/9-14</td>\n","      <td>1200.196001</td>\n","    </tr>\n","    <tr>\n","      <th>134287</th>\n","      <td>0.025832</td>\n","      <td>0.541467</td>\n","      <td>0.410217</td>\n","      <td>0.006205</td>\n","      <td>0.001658</td>\n","      <td>0.006824</td>\n","      <td>0.001278</td>\n","      <td>0.001141</td>\n","      <td>0.001139</td>\n","      <td>0.001440</td>\n","      <td>0.001731</td>\n","      <td>0.001068</td>\n","      <td>35/9-8</td>\n","      <td>2806.085600</td>\n","    </tr>\n","    <tr>\n","      <th>102017</th>\n","      <td>0.015090</td>\n","      <td>0.056390</td>\n","      <td>0.871212</td>\n","      <td>0.014132</td>\n","      <td>0.002466</td>\n","      <td>0.025756</td>\n","      <td>0.001766</td>\n","      <td>0.001578</td>\n","      <td>0.001574</td>\n","      <td>0.003199</td>\n","      <td>0.005361</td>\n","      <td>0.001476</td>\n","      <td>34/3-3 A</td>\n","      <td>3395.761976</td>\n","    </tr>\n","    <tr>\n","      <th>88577</th>\n","      <td>0.031000</td>\n","      <td>0.058304</td>\n","      <td>0.884758</td>\n","      <td>0.004227</td>\n","      <td>0.001601</td>\n","      <td>0.010710</td>\n","      <td>0.001154</td>\n","      <td>0.001031</td>\n","      <td>0.001029</td>\n","      <td>0.001301</td>\n","      <td>0.003919</td>\n","      <td>0.000965</td>\n","      <td>34/10-16 R</td>\n","      <td>3152.384008</td>\n","    </tr>\n","    <tr>\n","      <th>63886</th>\n","      <td>0.868795</td>\n","      <td>0.098474</td>\n","      <td>0.011409</td>\n","      <td>0.002865</td>\n","      <td>0.001475</td>\n","      <td>0.008152</td>\n","      <td>0.001037</td>\n","      <td>0.000926</td>\n","      <td>0.000924</td>\n","      <td>0.001169</td>\n","      <td>0.003907</td>\n","      <td>0.000867</td>\n","      <td>29/3-1</td>\n","      <td>3560.210001</td>\n","    </tr>\n","    <tr>\n","      <th>56012</th>\n","      <td>0.034715</td>\n","      <td>0.215972</td>\n","      <td>0.695144</td>\n","      <td>0.015206</td>\n","      <td>0.002188</td>\n","      <td>0.027921</td>\n","      <td>0.001531</td>\n","      <td>0.001368</td>\n","      <td>0.001365</td>\n","      <td>0.001726</td>\n","      <td>0.001584</td>\n","      <td>0.001280</td>\n","      <td>29/3-1</td>\n","      <td>2352.570001</td>\n","    </tr>\n","    <tr>\n","      <th>125908</th>\n","      <td>0.053565</td>\n","      <td>0.062956</td>\n","      <td>0.684520</td>\n","      <td>0.044442</td>\n","      <td>0.003681</td>\n","      <td>0.135596</td>\n","      <td>0.002636</td>\n","      <td>0.002355</td>\n","      <td>0.002349</td>\n","      <td>0.002970</td>\n","      <td>0.002726</td>\n","      <td>0.002203</td>\n","      <td>35/6-2 S</td>\n","      <td>2687.912467</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Sandstone  Sandstone/Shale     Shale  ...  Basement        WELL     DEPTH_MD\n","112406   0.022301         0.404550  0.543959  ...  0.001235    34/3-3 A  4975.345976\n","113793   0.214400         0.713408  0.046524  ...  0.001049    34/6-1 S  3532.682400\n","92619    0.024301         0.209458  0.748701  ...  0.001081  34/10-16 R  3766.768008\n","4725     0.022312         0.086483  0.867751  ...  0.000956     15/9-14  1200.196001\n","134287   0.025832         0.541467  0.410217  ...  0.001068      35/9-8  2806.085600\n","102017   0.015090         0.056390  0.871212  ...  0.001476    34/3-3 A  3395.761976\n","88577    0.031000         0.058304  0.884758  ...  0.000965  34/10-16 R  3152.384008\n","63886    0.868795         0.098474  0.011409  ...  0.000867      29/3-1  3560.210001\n","56012    0.034715         0.215972  0.695144  ...  0.001280      29/3-1  2352.570001\n","125908   0.053565         0.062956  0.684520  ...  0.002203    35/6-2 S  2687.912467\n","\n","[10 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"gIIZ5had1vaO","executionInfo":{"status":"ok","timestamp":1612645719894,"user_tz":360,"elapsed":368,"user":{"displayName":"Rafael Pinto","photoUrl":"","userId":"01213912175113627450"}},"outputId":"6ffcbae6-b07f-4600-a4c8-59f7b351a8e3"},"source":["model_proba.describe()"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sandstone</th>\n","      <th>Sandstone/Shale</th>\n","      <th>Shale</th>\n","      <th>Marl</th>\n","      <th>Dolomite</th>\n","      <th>Limestone</th>\n","      <th>Chalk</th>\n","      <th>Halite</th>\n","      <th>Anhydrite</th>\n","      <th>Tuff</th>\n","      <th>Coal</th>\n","      <th>Basement</th>\n","      <th>DEPTH_MD</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>136786.000000</td>\n","      <td>136786.000000</td>\n","      <td>136786.000000</td>\n","      <td>136786.000000</td>\n","      <td>136786.000000</td>\n","      <td>136786.000000</td>\n","      <td>136786.000000</td>\n","      <td>136786.000000</td>\n","      <td>136786.000000</td>\n","      <td>136786.000000</td>\n","      <td>136786.000000</td>\n","      <td>136786.000000</td>\n","      <td>136786.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.176065</td>\n","      <td>0.126915</td>\n","      <td>0.595028</td>\n","      <td>0.025959</td>\n","      <td>0.002634</td>\n","      <td>0.051319</td>\n","      <td>0.003319</td>\n","      <td>0.001318</td>\n","      <td>0.001422</td>\n","      <td>0.009904</td>\n","      <td>0.004989</td>\n","      <td>0.001125</td>\n","      <td>2501.136889</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.300827</td>\n","      <td>0.166179</td>\n","      <td>0.362935</td>\n","      <td>0.083961</td>\n","      <td>0.002984</td>\n","      <td>0.129162</td>\n","      <td>0.013375</td>\n","      <td>0.001284</td>\n","      <td>0.005449</td>\n","      <td>0.071746</td>\n","      <td>0.036165</td>\n","      <td>0.000847</td>\n","      <td>1043.245788</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000900</td>\n","      <td>0.001602</td>\n","      <td>0.002120</td>\n","      <td>0.000281</td>\n","      <td>0.000272</td>\n","      <td>0.000524</td>\n","      <td>0.000199</td>\n","      <td>0.000149</td>\n","      <td>0.000148</td>\n","      <td>0.000238</td>\n","      <td>0.000195</td>\n","      <td>0.000139</td>\n","      <td>227.296008</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.010992</td>\n","      <td>0.025541</td>\n","      <td>0.180512</td>\n","      <td>0.001855</td>\n","      <td>0.001017</td>\n","      <td>0.004508</td>\n","      <td>0.000824</td>\n","      <td>0.000617</td>\n","      <td>0.000607</td>\n","      <td>0.001120</td>\n","      <td>0.000851</td>\n","      <td>0.000564</td>\n","      <td>1707.948917</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.025460</td>\n","      <td>0.063841</td>\n","      <td>0.767943</td>\n","      <td>0.004847</td>\n","      <td>0.001838</td>\n","      <td>0.011537</td>\n","      <td>0.001338</td>\n","      <td>0.001044</td>\n","      <td>0.001031</td>\n","      <td>0.002118</td>\n","      <td>0.001545</td>\n","      <td>0.000957</td>\n","      <td>2471.823595</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.120014</td>\n","      <td>0.148030</td>\n","      <td>0.902895</td>\n","      <td>0.014212</td>\n","      <td>0.003059</td>\n","      <td>0.028297</td>\n","      <td>0.002113</td>\n","      <td>0.001639</td>\n","      <td>0.001624</td>\n","      <td>0.003030</td>\n","      <td>0.003124</td>\n","      <td>0.001493</td>\n","      <td>3294.643006</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>0.989718</td>\n","      <td>0.936320</td>\n","      <td>0.992646</td>\n","      <td>0.859589</td>\n","      <td>0.073862</td>\n","      <td>0.981689</td>\n","      <td>0.217454</td>\n","      <td>0.050720</td>\n","      <td>0.331511</td>\n","      <td>0.955967</td>\n","      <td>0.914423</td>\n","      <td>0.021042</td>\n","      <td>5007.417976</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Sandstone  Sandstone/Shale  ...       Basement       DEPTH_MD\n","count  136786.000000    136786.000000  ...  136786.000000  136786.000000\n","mean        0.176065         0.126915  ...       0.001125    2501.136889\n","std         0.300827         0.166179  ...       0.000847    1043.245788\n","min         0.000900         0.001602  ...       0.000139     227.296008\n","25%         0.010992         0.025541  ...       0.000564    1707.948917\n","50%         0.025460         0.063841  ...       0.000957    2471.823595\n","75%         0.120014         0.148030  ...       0.001493    3294.643006\n","max         0.989718         0.936320  ...       0.021042    5007.417976\n","\n","[8 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"NpCEeH0c16qR"},"source":[""],"execution_count":null,"outputs":[]}]}