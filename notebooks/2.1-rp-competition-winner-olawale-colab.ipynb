{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1659,
     "status": "ok",
     "timestamp": 1610892828247,
     "user": {
      "displayName": "Rafael Pinto",
      "photoUrl": "",
      "userId": "01213912175113627450"
     },
     "user_tz": 360
    },
    "id": "U4wK_1Sp5oZz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1704,
     "status": "ok",
     "timestamp": 1610892828304,
     "user": {
      "displayName": "Rafael Pinto",
      "photoUrl": "",
      "userId": "01213912175113627450"
     },
     "user_tz": 360
    },
    "id": "ff7CdOKkPise",
    "outputId": "a9808f2d-102a-4844-9dcf-6253bf91fb24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version is: 1.1.5\n",
      "numpy version is: 1.19.5\n",
      "matplotlib version is: 3.2.2\n",
      "sklearn version is: 0.22.2.post1\n",
      "xgboost version is: 0.90\n"
     ]
    }
   ],
   "source": [
    "# Print out packages versions\n",
    "print(f'pandas version is: {pd.__version__}')\n",
    "print(f'numpy version is: {np.__version__}')\n",
    "print(f'matplotlib version is: {matplotlib.__version__}')\n",
    "print(f'sklearn version is: {sklearn.__version__}')\n",
    "print(f'xgboost version is: {xgb.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdadWCzoPmJ_"
   },
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1698,
     "status": "ok",
     "timestamp": 1610892828309,
     "user": {
      "displayName": "Rafael Pinto",
      "photoUrl": "",
      "userId": "01213912175113627450"
     },
     "user_tz": 360
    },
    "id": "Z1HHu00J6gBZ"
   },
   "outputs": [],
   "source": [
    "def drop_columns(data, *args):\n",
    "    '''\n",
    "    function used to drop columns.\n",
    "    args: \n",
    "      data:  dataframe to be operated on\n",
    "      *args: a list of columns to be dropped from the dataframe\n",
    "\n",
    "    return: returns a dataframe with the columns dropped\n",
    "    '''\n",
    "    columns = []\n",
    "    for _ in args:\n",
    "        columns.append(_)\n",
    "        \n",
    "    data = data.drop(columns, axis=1)\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def process(data):\n",
    "    '''\n",
    "    function to process dataframe by replacing missing, infinity values with -999\n",
    "\n",
    "    args:: \n",
    "      data:  dataframe to be operated on\n",
    "    \n",
    "    returns dataframe with replaced values\n",
    "    '''\n",
    "    cols = list(data.columns)\n",
    "    for _ in cols:\n",
    "\n",
    "        data[_] = np.where(data[_] == np.inf, -999, data[_])\n",
    "        data[_] = np.where(data[_] == np.nan, -999, data[_])\n",
    "        data[_] = np.where(data[_] == -np.inf, -999, data[_])\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def show_evaluation(pred, true):\n",
    "    '''\n",
    "    function to show model performance and evaluation\n",
    "    args:\n",
    "      pred: predicted value(a list)\n",
    "      true: actual values (a list)\n",
    "      \n",
    "    prints the custom metric performance, accuracy and F1 score of predictions\n",
    "    '''\n",
    "    \n",
    "    print(f'Default score: {score(true.values, pred)}')\n",
    "    print(f'Accuracy is: {accuracy_score(true, pred)}')\n",
    "    print(f'F1 is: {f1_score(pred, true.values, average=\"weighted\")}')\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "#Paulo Bestagini's feature augmentation technique from SEG 2016 ML competition\n",
    "#Link : https://github.com/seg/2016-ml-contest/tree/master/ispl\n",
    "\n",
    "# Feature windows concatenation function\n",
    "def augment_features_window(X, N_neig):\n",
    "    # Parameters\n",
    "    N_row = X.shape[0]\n",
    "    N_feat = X.shape[1]\n",
    " \n",
    "    # Zero padding\n",
    "    X = np.vstack((np.zeros((N_neig, N_feat)), X, (np.zeros((N_neig, N_feat)))))\n",
    " \n",
    "    # Loop over windows\n",
    "    X_aug = np.zeros((N_row, N_feat*(2*N_neig+1)))\n",
    "    for r in np.arange(N_row)+N_neig:\n",
    "        this_row = []\n",
    "        for c in np.arange(-N_neig,N_neig+1):\n",
    "            this_row = np.hstack((this_row, X[r+c]))\n",
    "        X_aug[r-N_neig] = this_row\n",
    " \n",
    "    return X_aug\n",
    "\n",
    "\n",
    "# Feature gradient computation function\n",
    "def augment_features_gradient(X, depth):\n",
    "    \n",
    "    # Compute features gradient\n",
    "    d_diff = np.diff(depth).reshape((-1, 1))\n",
    "    d_diff[d_diff==0] = 0.001\n",
    "    X_diff = np.diff(X, axis=0)\n",
    "    X_grad = X_diff / d_diff\n",
    "        \n",
    "    # Compensate for last missing value\n",
    "    X_grad = np.concatenate((X_grad, np.zeros((1, X_grad.shape[1]))))\n",
    "    \n",
    "    return X_grad\n",
    "\n",
    "\n",
    "# Feature augmentation function\n",
    "def augment_features(X, well, depth, N_neig=1):\n",
    "    \n",
    "    # Augment features\n",
    "    X_aug = np.zeros((X.shape[0], X.shape[1]*(N_neig*2+2)))\n",
    "    for w in np.unique(well):\n",
    "        w_idx = np.where(well == w)[0]\n",
    "        X_aug_win = augment_features_window(X[w_idx, :], N_neig)\n",
    "        X_aug_grad = augment_features_gradient(X[w_idx, :], depth[w_idx])\n",
    "        X_aug[w_idx, :] = np.concatenate((X_aug_win, X_aug_grad), axis=1)\n",
    "    \n",
    "    # Find padded rows\n",
    "    padded_rows = np.unique(np.where(X_aug[:, 0:7] == np.zeros((1, 7)))[0])\n",
    "    \n",
    "    return X_aug, padded_rows\n",
    "\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    '''\n",
    "    custom metric used for evaluation\n",
    "    args:\n",
    "      y_true: actual prediction\n",
    "      y_pred: predictions made\n",
    "    '''\n",
    "    S = 0.0\n",
    "    y_true = y_true.astype(int)\n",
    "    y_pred = y_pred.astype(int)\n",
    "    for i in range(0, y_true.shape[0]):\n",
    "        S -= A[y_true[i], y_pred[i]]\n",
    "    return S/y_true.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g728BeHBP4Sk"
   },
   "source": [
    "# Import data\n",
    "\n",
    "First add a shortcut from the [google drive competition data location](https://drive.google.com/drive/folders/1GIkjq4fwgwbiqVQxYwoJnOJWVobZ91pL) to your own google drive. We will mount this drive, and access the data from it.\n",
    "\n",
    "We will save the results to a diffent folder, where we have write access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3255,
     "status": "ok",
     "timestamp": 1610892829878,
     "user": {
      "displayName": "Rafael Pinto",
      "photoUrl": "",
      "userId": "01213912175113627450"
     },
     "user_tz": 360
    },
    "id": "SMZi5ywWUCQV",
    "outputId": "7e6b9337-1a9b-48a1-d39e-9ee2378ab988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3250,
     "status": "ok",
     "timestamp": 1610892829881,
     "user": {
      "displayName": "Rafael Pinto",
      "photoUrl": "",
      "userId": "01213912175113627450"
     },
     "user_tz": 360
    },
    "id": "kSQfmlIWxBM8"
   },
   "outputs": [],
   "source": [
    "#should be edited to the present working directory of the user\n",
    "data_source = '/content/drive/My Drive/FORCE 2020 lithofacies prediction from well logs competition/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 12244,
     "status": "ok",
     "timestamp": 1610892838882,
     "user": {
      "displayName": "Rafael Pinto",
      "photoUrl": "",
      "userId": "01213912175113627450"
     },
     "user_tz": 360
    },
    "id": "1cLS1yO56iT_"
   },
   "outputs": [],
   "source": [
    "#importing penaltry matrix used for evaluation and train and test files\n",
    "A = np.load(data_source + 'penalty_matrix.npy')\n",
    "\n",
    "train = pd.read_csv(data_source + 'CSV_train.csv', sep=';')\n",
    "\n",
    "test = pd.read_csv(data_source + 'CSV_test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 12241,
     "status": "ok",
     "timestamp": 1610892838885,
     "user": {
      "displayName": "Rafael Pinto",
      "photoUrl": "",
      "userId": "01213912175113627450"
     },
     "user_tz": 360
    },
    "id": "aHEEU1t4Sow9"
   },
   "outputs": [],
   "source": [
    "# Destination folder\n",
    "out_data_dir = '/content/drive/My Drive/lith_pred/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 12236,
     "status": "ok",
     "timestamp": 1610892838886,
     "user": {
      "displayName": "Rafael Pinto",
      "photoUrl": "",
      "userId": "01213912175113627450"
     },
     "user_tz": 360
    },
    "id": "xQSZM0glXhPD"
   },
   "outputs": [],
   "source": [
    "class Model():\n",
    "    '''\n",
    "    class to lithology prediction\n",
    "    '''\n",
    "    \n",
    "    LITHOLOGY_ORDINAL_MAP = {\n",
    "        30000: 0,\n",
    "        65030: 1,\n",
    "        65000: 2,\n",
    "        80000: 3,\n",
    "        74000: 4,\n",
    "        70000: 5,\n",
    "        70032: 6,\n",
    "        88000: 7,\n",
    "        86000: 8,\n",
    "        99000: 9,\n",
    "        90000: 10,\n",
    "        93000: 11\n",
    "    }\n",
    "\n",
    "    def __init__(self, out_data_dir):\n",
    "      self.out_data_dir = out_data_dir\n",
    "\n",
    "\n",
    "    def preprocess(self, train, test):\n",
    "        '''\n",
    "        method to prepare datasets for training and predictions\n",
    "        accepts both the train and test dataframes as arguments\n",
    "\n",
    "        returns the prepared train, test datasets along with the\n",
    "        lithology labels and numbers which is needed for preparing\n",
    "        the submission file\n",
    "        '''\n",
    "        # Concatenating both train and test datasets for easier and uniform processing\n",
    "        ntrain = train.shape[0]\n",
    "        ntest = test.shape[0]\n",
    "        target = train.FORCE_2020_LITHOFACIES_LITHOLOGY.copy()\n",
    "        df = pd.concat((train, test)).reset_index(drop=True)\n",
    "\n",
    "        # Mapping the lithology labels to ordinal values for better modelling\n",
    "        lithology = train['FORCE_2020_LITHOFACIES_LITHOLOGY']\n",
    "        \n",
    "        lithology_ordinal = lithology.map(self.LITHOLOGY_ORDINAL_MAP)\n",
    "\n",
    "        # Implementing Bestagini's augmentation procedure\n",
    "        train_well = train.WELL.values\n",
    "        train_depth = train.DEPTH_MD.values\n",
    "        \n",
    "        test_well = test.WELL.values\n",
    "        test_depth = test.DEPTH_MD.values  \n",
    "        '''to be continued...\n",
    "        #this was done here for ease as the datasets would undergo some transformations\n",
    "        #that would make it uneasy to perform the augmentation technique'''\n",
    "\n",
    "\n",
    "        print(f'shape of concatenated dataframe before dropping columns {df.shape}')\n",
    "\n",
    "        cols = ['FORCE_2020_LITHOFACIES_CONFIDENCE', 'SGR', 'DTS', 'RXO', 'ROPA'] #columns to be dropped\n",
    "        df = drop_columns(df, *cols)\n",
    "        print(f'shape of dataframe after dropping columns {df.shape}')\n",
    "        print(f'{cols} were dropped')\n",
    "\n",
    "        # Label encoding the GROUP, FORMATION and WELLS features as these improved the performance of the models on validations\n",
    "        df['GROUP_encoded'] = df['GROUP'].astype('category')\n",
    "        df['GROUP_encoded'] = df['GROUP_encoded'].cat.codes \n",
    "        df['FORMATION_encoded'] = df['FORMATION'].astype('category')\n",
    "        df['FORMATION_encoded'] = df['FORMATION_encoded'].cat.codes\n",
    "        df['WELL_encoded'] = df['WELL'].astype('category')\n",
    "        df['WELL_encoded'] = df['WELL_encoded'].cat.codes\n",
    "        print(f'shape of dataframe after label encoding columns {df.shape}')\n",
    "\n",
    "\n",
    "        # FURTHER PREPRATION TO SPLIT DATAFRAME INTO TRAIN AND TEST DATASETS AFTER PREPRATION\n",
    "        print(f'Splitting concatenated dataframe into training and test datasets...')\n",
    "        df = df.drop(['WELL', 'GROUP', 'FORMATION'], axis=1)\n",
    "        print(df.shape)\n",
    "        \n",
    "        df = df.fillna(-999)\n",
    "        df = process(df)\n",
    "        data = df.copy()\n",
    "        \n",
    "        train2 = data[:ntrain].copy()\n",
    "        train2.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY'], axis=1, inplace=True)\n",
    "        \n",
    "        test2 = data[ntrain:(ntest+ntrain)].copy()\n",
    "        test2.drop(['FORCE_2020_LITHOFACIES_LITHOLOGY'], axis=1, inplace=True)\n",
    "        test2 = test2.reset_index(drop=True)\n",
    "\n",
    "        traindata = train2\n",
    "        testdata = test2\n",
    "\n",
    "        print(f'Shape of train and test datasets before augmentation {traindata.shape, testdata.shape}')\n",
    " \n",
    "        train_preprocess, padded_rows = augment_features(pd.DataFrame(traindata).values, train_well, train_depth)\n",
    "        test_preprocess, padded_rows = augment_features(pd.DataFrame(testdata).values, test_well, test_depth)\n",
    "        \n",
    "        print(f'Shape of train and test datasets after augmentation {train_preprocess.shape, test_preprocess.shape}')\n",
    "    \n",
    "        return train_preprocess, test_preprocess, lithology_ordinal\n",
    "\n",
    "    \n",
    "    def fit_predict(self, train_preprocess, test_preprocess, lithology_ordinal, plot=False):\n",
    "        '''\n",
    "        method to train model and make predictions\n",
    "\n",
    "        returns the test predictions, trained model, and lithology numbers used for making the submission file\n",
    "        '''\n",
    "        \n",
    "        # Using a 10-fold stratified cross-validation technique and seting the shuffle parameter to true\n",
    "        # as this improved the validation performance better\n",
    "        split = 10\n",
    "        kf = StratifiedKFold(n_splits=split, shuffle=True)\n",
    "\n",
    "        open_test = np.zeros((len(test_preprocess), 12))\n",
    "\n",
    "        # 100 n-estimators and 10 max-depth\n",
    "        model = XGBClassifier(n_estimators=100, max_depth=10, booster='gbtree',\n",
    "                              objective='multi:softprob', learning_rate=0.1, random_state=0,\n",
    "                              subsample=0.9, colsample_bytree=0.9, tree_method='gpu_hist',\n",
    "                              eval_metric='mlogloss', verbose=2020, reg_lambda=1500)\n",
    "\n",
    "\n",
    "        i = 1\n",
    "        for (train_index, test_index) in kf.split(pd.DataFrame(train_preprocess), pd.DataFrame(lithology_ordinal)):\n",
    "            X_train, X_test = pd.DataFrame(train_preprocess).iloc[train_index], pd.DataFrame(train_preprocess).iloc[test_index]\n",
    "            Y_train, Y_test = pd.DataFrame(lithology_ordinal).iloc[train_index],pd.DataFrame(lithology_ordinal).iloc[test_index]\n",
    "  \n",
    "            model.fit(X_train, Y_train, early_stopping_rounds=100, eval_set=[(X_test, Y_test)], verbose=100)\n",
    "            prediction = model.predict(X_test)\n",
    "            print(show_evaluation(prediction, Y_test))\n",
    "  \n",
    "            print(f'-----------------------FOLD {i}---------------------')\n",
    "            i+=1\n",
    "  \n",
    "            open_test += model.predict_proba(pd.DataFrame(test_preprocess))\n",
    "\n",
    "        open_test= pd.DataFrame(open_test/split)\n",
    "\n",
    "        open_test = np.array(pd.DataFrame(open_test).idxmax(axis=1))\n",
    "   \n",
    "        print('---------------CROSS VALIDATION COMPLETE')\n",
    "        print('----------------TEST EVALUATION------------------')\n",
    "  \n",
    "                  \n",
    "        if plot:\n",
    "            self.plot_feat_imp(model)\n",
    "            \n",
    "        return open_test, model\n",
    "              \n",
    "              \n",
    "    def plot_feat_imp(self, model):\n",
    "        feat_imp = pd.Series(model.feature_importances_).sort_values(ascending=False)\n",
    "        plt.figure(figsize=(12,8))\n",
    "        feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')\n",
    "        \n",
    "        return\n",
    "\n",
    "    def make_submission_file(self, train, test, filename):\n",
    "        '''\n",
    "        method to train model, make prediction and create submission file\n",
    "        args::\n",
    "          filename: name to save submission file as (string)\n",
    "        '''\n",
    "\n",
    "        train_preprocess, test_preprocess, lithology_ordinal = self.preprocess(train, test)\n",
    "\n",
    "        prediction, model = self.fit_predict(train_preprocess, test_preprocess, lithology_ordinal, plot=False)\n",
    "\n",
    "        category_to_lithology = {y:x for x,y in self.LITHOLOGY_ORDINAL_MAP.items()}\n",
    "        \n",
    "        test_prediction_for_submission = np.vectorize(category_to_lithology.get)(prediction)\n",
    "        \n",
    "        np.savetxt(self.out_data_dir + f'{filename}.csv',\n",
    "                   test_prediction_for_submission,\n",
    "                   header='lithology',\n",
    "                   fmt='%i')\n",
    "        return prediction, model, test_prediction_for_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "executionInfo": {
     "elapsed": 1170,
     "status": "error",
     "timestamp": 1610898400015,
     "user": {
      "displayName": "Rafael Pinto",
      "photoUrl": "",
      "userId": "01213912175113627450"
     },
     "user_tz": 360
    },
    "id": "t3dOrluJWtPM",
    "outputId": "f439b16f-49a3-4eeb-8631-59562ecf1e62"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4d1e2d4cba91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_data_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_prediction_for_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_submission_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'testing6'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-76b88fa3b027>\u001b[0m in \u001b[0;36mmake_submission_file\u001b[0;34m(self, train, test, filename)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mtrain_preprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlithology_ordinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_preprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_preprocess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlithology_ordinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mcategory_to_lithology\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLITHOLOGY_ORDINAL_MAP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-76b88fa3b027>\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, train_preprocess, test_preprocess, lithology_ordinal, plot)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlithology_ordinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlithology_ordinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#To train model and make prediction\n",
    "\n",
    "model = Model(out_data_dir)\n",
    "\n",
    "prediction, model, test_prediction_for_submission = model.make_submission_file(train, test, filename='testing6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1610821861746,
     "user": {
      "displayName": "Rafael Pinto",
      "photoUrl": "",
      "userId": "01213912175113627450"
     },
     "user_tz": 360
    },
    "id": "sueoRdaykxzp",
    "outputId": "ab70acc4-1164-4527-cf32-815a9f7e25ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1610821869203,
     "user": {
      "displayName": "Rafael Pinto",
      "photoUrl": "",
      "userId": "01213912175113627450"
     },
     "user_tz": 360
    },
    "id": "Fd45KJLVk3Ka"
   },
   "outputs": [],
   "source": [
    "#initializing the model class\n",
    "\n",
    "func_= Model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 806262,
     "status": "error",
     "timestamp": 1610822676301,
     "user": {
      "displayName": "Rafael Pinto",
      "photoUrl": "",
      "userId": "01213912175113627450"
     },
     "user_tz": 360
    },
    "id": "zRywwBE3mCb7",
    "outputId": "3647a822-86e3-4472-d06a-80fe4da674d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of concatenated dataframe before dropping columns (1307297, 29)\n",
      "shape of dataframe after dropping columns (1307297, 24)\n",
      "['FORCE_2020_LITHOFACIES_CONFIDENCE', 'SGR', 'DTS', 'RXO', 'ROPA'] were dropped\n",
      "shape of dataframe after label encoding columns (1307297, 27)\n",
      "Splitting concatenated dataframe into training and test datasets...\n",
      "(1307297, 24)\n",
      "Shape of train and test datasets before augmentation ((1170511, 23), (136786, 23))\n",
      "Shape of train and test datasets after augmentation ((1170511, 92), (136786, 92))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.165\n",
      "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-mlogloss:0.322635\n",
      "Default score: [-0.27953922]\n",
      "Accuracy is: 0.8936626456617571\n",
      "F1 is: 0.8976340466088769\n",
      "None\n",
      "-----------------------FOLD 1---------------------\n",
      "[0]\tvalidation_0-mlogloss:2.16379\n",
      "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-mlogloss:0.317198\n",
      "Default score: [-0.27461854]\n",
      "Accuracy is: 0.8957975583292753\n",
      "F1 is: 0.8996824238310795\n",
      "None\n",
      "-----------------------FOLD 2---------------------\n",
      "[0]\tvalidation_0-mlogloss:2.16423\n",
      "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-mlogloss:0.318207\n",
      "Default score: [-0.27783082]\n",
      "Accuracy is: 0.8942768536791655\n",
      "F1 is: 0.8982109463516271\n",
      "None\n",
      "-----------------------FOLD 3---------------------\n",
      "[0]\tvalidation_0-mlogloss:2.16511\n",
      "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-mlogloss:0.320233\n",
      "Default score: [-0.27953413]\n",
      "Accuracy is: 0.8937129968987877\n",
      "F1 is: 0.8977205785673666\n",
      "None\n",
      "-----------------------FOLD 4---------------------\n",
      "[0]\tvalidation_0-mlogloss:2.16416\n",
      "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-mlogloss:0.318276\n",
      "Default score: [-0.2779344]\n",
      "Accuracy is: 0.8945673253539056\n",
      "F1 is: 0.8984158274655312\n",
      "None\n",
      "-----------------------FOLD 5---------------------\n",
      "[0]\tvalidation_0-mlogloss:2.16443\n",
      "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-mlogloss:0.318172\n",
      "Default score: [-0.27814585]\n",
      "Accuracy is: 0.8939094924434648\n",
      "F1 is: 0.8977220514897667\n",
      "None\n",
      "-----------------------FOLD 6---------------------\n",
      "[0]\tvalidation_0-mlogloss:2.16438\n",
      "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-mlogloss:0.3189\n",
      "Default score: [-0.27744317]\n",
      "Accuracy is: 0.894208507402756\n",
      "F1 is: 0.8981487966085818\n",
      "None\n",
      "-----------------------FOLD 7---------------------\n",
      "[0]\tvalidation_0-mlogloss:2.16451\n",
      "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-mlogloss:0.317982\n",
      "Default score: [-0.27716978]\n",
      "Accuracy is: 0.8944135462319843\n",
      "F1 is: 0.8984344033103698\n",
      "None\n",
      "-----------------------FOLD 8---------------------\n",
      "[0]\tvalidation_0-mlogloss:2.16367\n",
      "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-mlogloss:0.319819\n",
      "Default score: [-0.27830177]\n",
      "Accuracy is: 0.8945673253539056\n",
      "F1 is: 0.8985679378070082\n",
      "None\n",
      "-----------------------FOLD 9---------------------\n",
      "[0]\tvalidation_0-mlogloss:2.16432\n",
      "Will train until validation_0-mlogloss hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-mlogloss:0.319266\n",
      "Default score: [-0.27902367]\n",
      "Accuracy is: 0.8942853969637167\n",
      "F1 is: 0.898193912152875\n",
      "None\n",
      "-----------------------FOLD 10---------------------\n",
      "---------------CROSS VALIDATION COMPLETE\n",
      "----------------TEST EVALUATION------------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-cb5720ba5a66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#using the make_submission_file method to make predicction and create a submission file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfunc_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_submission_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'testing6'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-edc9812aa6e4>\u001b[0m in \u001b[0;36mmake_submission_file\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    188\u001b[0m       \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPWD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m       \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPWD\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m       \u001b[0mcategory_to_lithology\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlithology_numbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/FORCE 2020 lithofacies prediction from well logs competition/Test.csv'"
     ]
    }
   ],
   "source": [
    "#using the make_submission_file method to make predicction and create a submission file\n",
    "\n",
    "func_.make_submission_file(filename='testing6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "SmxsGsBWmtAp",
    "outputId": "66e36d27-2645-4d7c-c81f-01116a353e31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65000    97125\n",
       "30000    24010\n",
       "65030     9027\n",
       "70000     4754\n",
       "99000      988\n",
       "80000      456\n",
       "90000      401\n",
       "86000       25\n",
       "Name: # lithology, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv('/content/drive/My Drive/FORCE-Lithology-Prediction/testing4.csv')\n",
    " \n",
    "a['# lithology'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "id": "-4DZpnEReqb9",
    "outputId": "9740c84a-4d27-4a53-c731-8827f81425c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65000    94447\n",
       "30000    24831\n",
       "65030    10489\n",
       "70000     5817\n",
       "80000      610\n",
       "99000      511\n",
       "90000       63\n",
       "86000       16\n",
       "88000        2\n",
       "Name: # lithology, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv('/content/drive/My Drive/FORCE-Lithology-Prediction/testing6.csv')\n",
    " \n",
    "a['# lithology'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mu6R4oHsewc8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2.0-rp-competition-winner-olawale..ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/bolgebrygg/Force-2020-Machine-Learning-competition/blob/master/lithology_competition/code/OlawaleI/FORCE_Submission_File.ipynb",
     "timestamp": 1610818622861
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
